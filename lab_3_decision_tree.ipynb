{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy.io import arff\n",
    "from scipy import stats\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. (40%) Correctly implement the ID3 decision tree algorithm, including the ability to handle unknown attributes (You do not need to handle real valued attributes).  \n",
    "### Code Requirements/Notes:\n",
    "- Use standard information gain as your basic attribute evaluation metric.  (Note that normal ID3 would usually augment information gain with gain ratio or some other mechanism to penalize statistically insignificant attribute splits. Otherwise, even with approaches like pruning below, the SSE type of overfit could still hurt us.) \n",
    "- You are welcome to create other classes and/or functions in addition to the ones provided below. (e.g. If you build out a tree structure, you might create a node class).\n",
    "- It is a good idea to use a simple data set (like the lenses data or the pizza homework), which you can check by hand, to test your algorithm to make sure that it is working correctly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node():\n",
    "    def __init__(self, name, used, X, y):\n",
    "        self.name = name\n",
    "        self.children = []\n",
    "        self.used = used\n",
    "        self.split = None\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "class Tree():\n",
    "    def __init__(self, root):\n",
    "        self.gains = []\n",
    "        self.root = root\n",
    "        \n",
    "    def dive(self, start, X):\n",
    "        if len(start.children) > 0:\n",
    "            ind = None\n",
    "            for i in range(len(start.children)):\n",
    "                if start.children[i].name == X[start.split]:\n",
    "                    ind = i\n",
    "            if ind is not None:\n",
    "                return self.dive(start.children[ind], X)\n",
    "            else:\n",
    "                return stats.mode(start.y)[0][0]\n",
    "        else:\n",
    "            return stats.mode(start.y)[0][0]\n",
    "    \n",
    "    def dive_print(self, start, indent):\n",
    "        if len(start.children) > 0:\n",
    "            for i in start.children:\n",
    "                print(indent + \"feature \" + str(start.split) + \" = \" + str(i.name))\n",
    "                self.dive_print(i, indent + \"   \")\n",
    "        else:\n",
    "            print(indent + \"prediction = \" + str(stats.mode(start.y)[0][0]))\n",
    "    \n",
    "    def add_kids(self, start, gain):\n",
    "        if np.unique(start.y).shape[0] > 1:\n",
    "            info_gain = gain(start.X, start.y, start.used)\n",
    "            if np.amax(info_gain) > 0:\n",
    "                split = np.argmax(info_gain)\n",
    "                self.gains.append(info_gain[split])\n",
    "                start.split = split\n",
    "                vals = np.unique(start.X[:,split])\n",
    "                new_used = np.array(start.used)\n",
    "                new_used[split] = 1\n",
    "                for i in vals:\n",
    "                    rows = np.where(start.X[:,split]==i)\n",
    "                    new_X = None\n",
    "                    new_y = None\n",
    "                    for j in rows:\n",
    "                        if new_X is None:\n",
    "                            new_X = start.X[j]\n",
    "                            new_y = start.y[j]\n",
    "                        else:\n",
    "                            new_X = np.concatenate((new_X, start.X[j]))\n",
    "                            new_y = np.concatenate((new_y, start.y[j]))\n",
    "                    node = Node(i, new_used, new_X, new_y)\n",
    "                    start.children.append(node)\n",
    "                    self.add_kids(node, gain)\n",
    "                    \n",
    "\n",
    "class DTClassifier(BaseEstimator,ClassifierMixin):\n",
    "\n",
    "    def __init__(self,counts=None):\n",
    "        \"\"\" Initialize class with chosen hyperparameters.\n",
    "        Args:\n",
    "        Optional Args (Args we think will make your life easier):\n",
    "            counts: A list of Ints that tell you how many types of each feature there are\n",
    "        Example:\n",
    "            DT  = DTClassifier()\n",
    "            or\n",
    "            DT = DTClassifier(count = [2,3,2,2])\n",
    "            Dataset = \n",
    "            [[0,1,0,0],\n",
    "            [1,2,1,1],\n",
    "            [0,1,1,0],\n",
    "            [1,2,0,1],\n",
    "            [0,0,1,1]]\n",
    "\n",
    "        \"\"\"\n",
    "        if counts != None:\n",
    "            self.counts = counts\n",
    "        \n",
    "        else:\n",
    "            self.counts = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\" Fit the data; Make the Decision tree\n",
    "\n",
    "        Args:\n",
    "            X (array-like): A 2D numpy array with the training data, excluding targets\n",
    "            y (array-like): A 1D numpy array with the training targets\n",
    "\n",
    "        Returns:\n",
    "            self: this allows this to be chained, e.g. model.fit(X,y).predict(X_test)\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        used = np.zeros(X.shape[1])\n",
    "        \n",
    "        root = Node('root', used, X, y)\n",
    "        \n",
    "        self.tree = Tree(root)\n",
    "        self.tree.add_kids(root, self.get_gain)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def get_gain(self, X, y, used):\n",
    "        \n",
    "        self.classes = np.unique(y)\n",
    "        \n",
    "        class_percents = np.zeros(self.classes.size)\n",
    "        for i in range(self.classes.size):\n",
    "            class_percents[i] = np.count_nonzero(y == self.classes[i]) / y.size\n",
    "\n",
    "        class_info = 0.\n",
    "        \n",
    "        for i in class_percents:\n",
    "            class_info += -i * math.log(i, 2)\n",
    "\n",
    "        gain = np.zeros(X.shape[1])\n",
    "            \n",
    "        for i in range(X.shape[1]):\n",
    "            if used[i] == 0:\n",
    "                vals = np.unique(X[:,i])\n",
    "                for j in vals:\n",
    "                    at_count = np.count_nonzero(X[:,i]==j)\n",
    "                    at_percent = at_count / X.shape[0]\n",
    "                    inf = 0\n",
    "                    for k in self.classes:\n",
    "                        tally = 0\n",
    "                        locations = np.where(X[:,i]==j)[0]\n",
    "                        for m in range(locations.size):\n",
    "                            if y[locations[m]] == k:\n",
    "                                tally += 1\n",
    "\n",
    "                        if tally > 0:\n",
    "                            inf += (-tally / at_count) * math.log(tally / at_count, 2)\n",
    "\n",
    "                    gain[i] += at_percent * inf\n",
    "                gain[i] = class_info - gain[i]\n",
    "        \n",
    "        return gain\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\" Predict all classes for a dataset X\n",
    "\n",
    "        Args:\n",
    "            X (array-like): A 2D numpy array with the training data, excluding targets\n",
    "\n",
    "        Returns:\n",
    "            array, shape (n_samples,)\n",
    "                Predicted target values per element in X.\n",
    "        \"\"\"\n",
    "        \n",
    "        y = None\n",
    "        \n",
    "        for i in X:\n",
    "            guess = self.tree.dive(self.tree.root, i)\n",
    "            if y is None:\n",
    "                y = np.array([guess])\n",
    "            else:\n",
    "                y = np.concatenate((y, [guess]))\n",
    "        return y\n",
    "\n",
    "    def score(self, X, y):\n",
    "        \"\"\" Return accuracy(Classification Acc) of model on a given dataset. Must implement own score function.\n",
    "\n",
    "        Args:\n",
    "            X (array-like): A 2D numpy array with data, excluding targets\n",
    "            y (array-like): A 1D numpy array of the targets \n",
    "        \"\"\"\n",
    "        \n",
    "        prediction = self.predict(X)\n",
    "        \n",
    "        correct_count = 0\n",
    "        \n",
    "        for i in range(len(prediction)):\n",
    "            if y[i] == prediction[i]:\n",
    "                correct_count += 1\n",
    "        \n",
    "        return correct_count / y.shape[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Debug\n",
    "\n",
    "Debug your model by training on the lenses dataset: [Debug Dataset](https://raw.githubusercontent.com/cs472ta/CS472/master/datasets/lenses.arff)\n",
    "\n",
    "Test your model on the lenses test set: [Debug Test Dataset](https://raw.githubusercontent.com/cs472ta/CS472/master/datasets/lenses_test.arff)\n",
    "\n",
    "Parameters:\n",
    "(optional) counts = [3,2,2,2] (You should compute this when you read in the data, before fitting)\n",
    "\n",
    "---\n",
    "\n",
    "Expected Results: Accuracy = [0.33]\n",
    "\n",
    "Predictions should match this file: [Lenses Predictions](https://raw.githubusercontent.com/cs472ta/CS472/master/debug_solutions/pred_lenses.csv)\n",
    "\n",
    "Split Information Gains (These do not need to be in this exact order):\n",
    "\n",
    "[0.5487949406953987, 0.7704260414863775, 0.3166890883150208, 1.0, 0.4591479170272447, 0.9182958340544894]\n",
    "\n",
    "<!-- You should be able to get about 68% (61%-82%) predictive accuracy on the lenses data -->\n",
    "\n",
    "Here's what your decision tree splits should look like, and the corresponding child node predictions:\n",
    "\n",
    "Decision Tree:\n",
    "<pre>\n",
    "feature_3 = 0:\n",
    "\tfeature_2 = 0:\n",
    "\t\tfeature_0 = 0:\n",
    "\t\t\tprediction: 2\n",
    "\t\tfeature_0 = 1:\n",
    "\t\t\tfeature_1 = 0:\n",
    "\t\t\t\tprediction: 2\n",
    "\t\t\tfeature_1 = 1:\n",
    "\t\t\t\tprediction: 1\n",
    "\t\tfeature_0 = 2:\n",
    "\t\t\tprediction: 2\n",
    "\tfeature_2 = 1:\n",
    "\t\tfeature_1 = 0:\n",
    "\t\t\tfeature_0 = 0:\n",
    "\t\t\t\tprediction: 1\n",
    "\t\t\tfeature_0 = 1:\n",
    "\t\t\t\tprediction: 1\n",
    "\t\t\tfeature_0 = 2:\n",
    "\t\t\t\tprediction: 0\n",
    "\t\tfeature_1 = 1:\n",
    "\t\t\tprediction: 0\n",
    "feature_3 = 1:\n",
    "\tprediction: 1\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3333333333333333\n",
      "[0.5487949406953985, 0.7704260414863778, 0.3166890883150208, 1.0, 0.4591479170272448, 0.9182958340544896]\n",
      "feature 3 = normal\n",
      "   feature 2 = no\n",
      "      feature 0 = pre_presbyopi\n",
      "         prediction = ['soft']\n",
      "      feature 0 = presbyopic\n",
      "         feature 1 = hypermetrope\n",
      "            prediction = ['soft']\n",
      "         feature 1 = myope\n",
      "            prediction = ['none']\n",
      "      feature 0 = young\n",
      "         prediction = ['soft']\n",
      "   feature 2 = yes\n",
      "      feature 1 = hypermetrope\n",
      "         feature 0 = pre_presbyopi\n",
      "            prediction = ['none']\n",
      "         feature 0 = presbyopic\n",
      "            prediction = ['none']\n",
      "         feature 0 = young\n",
      "            prediction = ['hard']\n",
      "      feature 1 = myope\n",
      "         prediction = ['hard']\n",
      "feature 3 = reduced\n",
      "   prediction = ['none']\n"
     ]
    }
   ],
   "source": [
    "# Load debug training data \n",
    "\n",
    "data = arff.loadarff('datasets/lenses.arff')\n",
    "df = pd.DataFrame(data[0])\n",
    "data = np.array(df)\n",
    "\n",
    "X = data[:,:-1].astype(\"U13\")\n",
    "y = np.reshape([data[:,-1]], (-1,1)).astype(\"U13\")\n",
    "\n",
    "# Train Decision Tree\n",
    "\n",
    "DT = DTClassifier()\n",
    "DT.fit(X,y)\n",
    "\n",
    "# Load debug test data\n",
    "\n",
    "data = arff.loadarff('datasets/lenses_test.arff')\n",
    "df = pd.DataFrame(data[0])\n",
    "data = np.array(df)\n",
    "\n",
    "test_X = data[:,:-1].astype(\"U13\")\n",
    "test_y = np.reshape([data[:,-1]], (-1,1)).astype(\"U13\")\n",
    "\n",
    "\n",
    "# Predict and compute model accuracy\n",
    "\n",
    "print(DT.score(test_X, test_y))\n",
    "\n",
    "# Print the information gain of every split you make.\n",
    "\n",
    "print(DT.tree.gains)\n",
    "DT.tree.dive_print(DT.tree.root,\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional/Additional Debugging Dataset - Pizza Homework\n",
    "# pizza_dataset = np.array([[1,2,0],[0,0,0],[0,1,1],[1,1,1],[1,0,0],[1,0,1],[0,2,1],[1,0,0],[0,2,0]])\n",
    "# pizza_labels = np.array([2,0,1,2,1,2,1,1,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Evaluation\n",
    "\n",
    "We will evaluate your model based on its performance on the zoo dataset. \n",
    "\n",
    "Train your model using this dataset: [Evaluation Train Dataset](https://raw.githubusercontent.com/cs472ta/CS472/master/datasets/zoo.arff)\n",
    "\n",
    "Test your model on this dataset: [Evaluation Test Dataset](https://raw.githubusercontent.com/cs472ta/CS472/master/datasets/zoo_test.arff)\n",
    "\n",
    "Parameters:\n",
    "(optional) counts = [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 6, 2, 2, 2] (You should compute this when you read in the data, before fitting)\n",
    "\n",
    "---\n",
    "Print out your accuracy on the evaluation test dataset.\n",
    "\n",
    "Print out the information gain of every split you make."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.147\n",
      "[1.3630469031539394, 0.8865408928220899, 0.9852281360342516, 0.6962122601251458, 0.8256265261578954, 0.6892019851173655, 0.863120568566631, 0.7219280948873623, 0.7219280948873623]\n"
     ]
    }
   ],
   "source": [
    "# Load evaluation training data\n",
    "\n",
    "data = arff.loadarff('datasets/zoo.arff')\n",
    "df = pd.DataFrame(data[0])\n",
    "data = np.array(df)\n",
    "\n",
    "eval_train_X = data[:,:-1].astype(\"U13\")\n",
    "eval_train_y = np.reshape([data[:,-1]], (-1,1)).astype(\"U13\")\n",
    "\n",
    "# Train Decision Tree\n",
    "\n",
    "DTE = DTClassifier()\n",
    "DTE.fit(eval_train_X, eval_train_y)\n",
    "\n",
    "# Load evaluation test data\n",
    "\n",
    "data = arff.loadarff('datasets/zoo_test.arff')\n",
    "df = pd.DataFrame(data[0])\n",
    "data = np.array(df)\n",
    "\n",
    "eval_test_X = data[:,:-1].astype(\"U13\")\n",
    "eval_test_y = np.reshape([data[:,-1]], (-1,1)).astype(\"U13\")\n",
    "\n",
    "print(DTE.score(eval_test_X, eval_test_y))\n",
    "\n",
    "# Print out the information gain for every split you make\n",
    "\n",
    "print(DTE.tree.gains)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. (20%) You will use your ID3 algorithm to induce decision trees for the cars dataset and the voting dataset.  Do not use a stopping criteria, but induce the tree as far as it can go (until classes are pure or there are no more data or attributes to split on).  \n",
    "- Implement and use 10-fold Cross Validation (CV) on each data set to predict how well the models will do on novel data.  \n",
    "- For each dataset, report the training and test classification accuracy for each fold and the average test accuracy. \n",
    "- As a rough sanity check, typical decision tree accuracies for these data sets are: Cars: .90-.95, Vote: .92-.95."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Implement 10-fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a function that implements 10-fold cross validation\n",
    "\n",
    "def cross_val_10(model, data, results):\n",
    "    all_data = np.concatenate((data,results), axis=1)\n",
    "    np.random.shuffle(all_data)\n",
    "    data = all_data[:,:-1]\n",
    "    results = all_data[:,-1]\n",
    "    \n",
    "    train_acc = []\n",
    "    test_acc = []\n",
    "    \n",
    "    set_size = data.shape[0] // 10\n",
    "    \n",
    "    DT = None\n",
    "    \n",
    "    for i in range(10):\n",
    "            train_set = np.concatenate((data[:i*set_size], data[(i+1)* set_size:]))\n",
    "            train_set_results = np.concatenate((results[:i*set_size], results[(i+1)* set_size:]))\n",
    "            DT = model()\n",
    "            DT.fit(train_set, train_set_results)\n",
    "            train_acc.append(DT.score(train_set, train_set_results))\n",
    "            test_acc.append(DT.score(data[i*set_size:(i+1)*set_size], results[i*set_size:(i+1)*set_size]))\n",
    "            \n",
    "    return train_acc, test_acc, sum(test_acc) / len(test_acc), DT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  2.2 Cars Dataset\n",
    "- Use this [Cars Dataset](https://raw.githubusercontent.com/cs472ta/CS472/master/datasets/cars.arff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "[0.9011627906976745, 0.9418604651162791, 0.9941860465116279, 0.9534883720930233, 0.9302325581395349, 0.9476744186046512, 0.9534883720930233, 0.9418604651162791, 0.936046511627907, 0.936046511627907]\n",
      "0.9436046511627907\n",
      "feature 5 = high\n",
      "   feature 3 = 2\n",
      "      prediction = unacc\n",
      "   feature 3 = 4\n",
      "      feature 0 = high\n",
      "         feature 1 = high\n",
      "            prediction = acc\n",
      "         feature 1 = low\n",
      "            prediction = acc\n",
      "         feature 1 = med\n",
      "            prediction = acc\n",
      "         feature 1 = vhigh\n",
      "            prediction = unacc\n",
      "      feature 0 = low\n",
      "         feature 1 = high\n",
      "            feature 4 = big\n",
      "               prediction = vgood\n",
      "            feature 4 = med\n",
      "               feature 2 = 2\n",
      "                  prediction = acc\n",
      "               feature 2 = 3\n",
      "                  prediction = acc\n",
      "               feature 2 = 4\n",
      "                  prediction = vgood\n",
      "               feature 2 = 5more\n",
      "                  prediction = vgood\n",
      "            feature 4 = small\n",
      "               prediction = acc\n",
      "         feature 1 = low\n",
      "            feature 4 = big\n",
      "               prediction = vgood\n",
      "            feature 4 = med\n",
      "               feature 2 = 2\n",
      "                  prediction = good\n",
      "               feature 2 = 3\n",
      "                  prediction = good\n",
      "               feature 2 = 4\n",
      "                  prediction = vgood\n",
      "            feature 4 = small\n",
      "               prediction = good\n",
      "         feature 1 = med\n",
      "            feature 4 = big\n",
      "               prediction = vgood\n",
      "            feature 4 = med\n",
      "               feature 2 = 2\n",
      "                  prediction = good\n",
      "               feature 2 = 3\n",
      "                  prediction = good\n",
      "               feature 2 = 4\n",
      "                  prediction = vgood\n",
      "               feature 2 = 5more\n",
      "                  prediction = vgood\n",
      "            feature 4 = small\n",
      "               prediction = good\n",
      "         feature 1 = vhigh\n",
      "            prediction = acc\n",
      "      feature 0 = med\n",
      "         feature 1 = high\n",
      "            prediction = acc\n",
      "         feature 1 = low\n",
      "            feature 4 = big\n",
      "               prediction = vgood\n",
      "            feature 4 = med\n",
      "               feature 2 = 2\n",
      "                  prediction = good\n",
      "               feature 2 = 3\n",
      "                  prediction = good\n",
      "               feature 2 = 4\n",
      "                  prediction = vgood\n",
      "               feature 2 = 5more\n",
      "                  prediction = vgood\n",
      "            feature 4 = small\n",
      "               prediction = good\n",
      "         feature 1 = med\n",
      "            feature 4 = big\n",
      "               prediction = vgood\n",
      "            feature 4 = med\n",
      "               feature 2 = 2\n",
      "                  prediction = acc\n",
      "               feature 2 = 4\n",
      "                  prediction = vgood\n",
      "               feature 2 = 5more\n",
      "                  prediction = vgood\n",
      "            feature 4 = small\n",
      "               prediction = acc\n",
      "         feature 1 = vhigh\n",
      "            prediction = acc\n",
      "      feature 0 = vhigh\n",
      "         feature 1 = high\n",
      "            prediction = unacc\n",
      "         feature 1 = low\n",
      "            prediction = acc\n",
      "         feature 1 = med\n",
      "            prediction = acc\n",
      "         feature 1 = vhigh\n",
      "            prediction = unacc\n",
      "   feature 3 = more\n",
      "      feature 0 = high\n",
      "         feature 1 = high\n",
      "            feature 2 = 2\n",
      "               feature 4 = big\n",
      "                  prediction = acc\n",
      "               feature 4 = med\n",
      "                  prediction = acc\n",
      "               feature 4 = small\n",
      "                  prediction = unacc\n",
      "            feature 2 = 3\n",
      "               prediction = acc\n",
      "            feature 2 = 4\n",
      "               prediction = acc\n",
      "            feature 2 = 5more\n",
      "               prediction = acc\n",
      "         feature 1 = low\n",
      "            feature 2 = 2\n",
      "               feature 4 = big\n",
      "                  prediction = acc\n",
      "               feature 4 = med\n",
      "                  prediction = acc\n",
      "               feature 4 = small\n",
      "                  prediction = unacc\n",
      "            feature 2 = 3\n",
      "               prediction = acc\n",
      "            feature 2 = 4\n",
      "               prediction = acc\n",
      "            feature 2 = 5more\n",
      "               prediction = acc\n",
      "         feature 1 = med\n",
      "            feature 2 = 2\n",
      "               feature 4 = big\n",
      "                  prediction = acc\n",
      "               feature 4 = small\n",
      "                  prediction = unacc\n",
      "            feature 2 = 3\n",
      "               prediction = acc\n",
      "            feature 2 = 4\n",
      "               prediction = acc\n",
      "            feature 2 = 5more\n",
      "               prediction = acc\n",
      "         feature 1 = vhigh\n",
      "            prediction = unacc\n",
      "      feature 0 = low\n",
      "         feature 1 = high\n",
      "            feature 4 = big\n",
      "               prediction = vgood\n",
      "            feature 4 = med\n",
      "               feature 2 = 2\n",
      "                  prediction = acc\n",
      "               feature 2 = 3\n",
      "                  prediction = vgood\n",
      "               feature 2 = 4\n",
      "                  prediction = vgood\n",
      "               feature 2 = 5more\n",
      "                  prediction = vgood\n",
      "            feature 4 = small\n",
      "               prediction = acc\n",
      "         feature 1 = low\n",
      "            feature 4 = big\n",
      "               prediction = vgood\n",
      "            feature 4 = med\n",
      "               prediction = vgood\n",
      "            feature 4 = small\n",
      "               feature 2 = 2\n",
      "                  prediction = unacc\n",
      "               feature 2 = 3\n",
      "                  prediction = good\n",
      "               feature 2 = 4\n",
      "                  prediction = good\n",
      "               feature 2 = 5more\n",
      "                  prediction = good\n",
      "         feature 1 = med\n",
      "            feature 4 = big\n",
      "               prediction = vgood\n",
      "            feature 4 = med\n",
      "               feature 2 = 2\n",
      "                  prediction = good\n",
      "               feature 2 = 3\n",
      "                  prediction = vgood\n",
      "            feature 4 = small\n",
      "               feature 2 = 2\n",
      "                  prediction = unacc\n",
      "               feature 2 = 3\n",
      "                  prediction = good\n",
      "               feature 2 = 4\n",
      "                  prediction = good\n",
      "               feature 2 = 5more\n",
      "                  prediction = good\n",
      "         feature 1 = vhigh\n",
      "            feature 2 = 2\n",
      "               feature 4 = big\n",
      "                  prediction = acc\n",
      "               feature 4 = med\n",
      "                  prediction = acc\n",
      "               feature 4 = small\n",
      "                  prediction = unacc\n",
      "            feature 2 = 3\n",
      "               prediction = acc\n",
      "            feature 2 = 4\n",
      "               prediction = acc\n",
      "            feature 2 = 5more\n",
      "               prediction = acc\n",
      "      feature 0 = med\n",
      "         feature 1 = high\n",
      "            feature 2 = 2\n",
      "               feature 4 = big\n",
      "                  prediction = acc\n",
      "               feature 4 = med\n",
      "                  prediction = acc\n",
      "               feature 4 = small\n",
      "                  prediction = unacc\n",
      "            feature 2 = 3\n",
      "               prediction = acc\n",
      "            feature 2 = 4\n",
      "               prediction = acc\n",
      "            feature 2 = 5more\n",
      "               prediction = acc\n",
      "         feature 1 = low\n",
      "            feature 4 = big\n",
      "               prediction = vgood\n",
      "            feature 4 = med\n",
      "               feature 2 = 2\n",
      "                  prediction = good\n",
      "               feature 2 = 3\n",
      "                  prediction = vgood\n",
      "               feature 2 = 4\n",
      "                  prediction = vgood\n",
      "               feature 2 = 5more\n",
      "                  prediction = vgood\n",
      "            feature 4 = small\n",
      "               feature 2 = 2\n",
      "                  prediction = unacc\n",
      "               feature 2 = 3\n",
      "                  prediction = good\n",
      "               feature 2 = 4\n",
      "                  prediction = good\n",
      "               feature 2 = 5more\n",
      "                  prediction = good\n",
      "         feature 1 = med\n",
      "            feature 4 = big\n",
      "               prediction = vgood\n",
      "            feature 4 = med\n",
      "               feature 2 = 2\n",
      "                  prediction = acc\n",
      "               feature 2 = 3\n",
      "                  prediction = vgood\n",
      "               feature 2 = 4\n",
      "                  prediction = vgood\n",
      "               feature 2 = 5more\n",
      "                  prediction = vgood\n",
      "            feature 4 = small\n",
      "               feature 2 = 2\n",
      "                  prediction = unacc\n",
      "               feature 2 = 3\n",
      "                  prediction = acc\n",
      "               feature 2 = 4\n",
      "                  prediction = acc\n",
      "               feature 2 = 5more\n",
      "                  prediction = acc\n",
      "         feature 1 = vhigh\n",
      "            feature 2 = 2\n",
      "               feature 4 = big\n",
      "                  prediction = acc\n",
      "               feature 4 = med\n",
      "                  prediction = acc\n",
      "               feature 4 = small\n",
      "                  prediction = unacc\n",
      "            feature 2 = 3\n",
      "               prediction = acc\n",
      "            feature 2 = 4\n",
      "               prediction = acc\n",
      "            feature 2 = 5more\n",
      "               prediction = acc\n",
      "      feature 0 = vhigh\n",
      "         feature 1 = high\n",
      "            prediction = unacc\n",
      "         feature 1 = low\n",
      "            feature 2 = 2\n",
      "               feature 4 = med\n",
      "                  prediction = acc\n",
      "               feature 4 = small\n",
      "                  prediction = unacc\n",
      "            feature 2 = 3\n",
      "               prediction = acc\n",
      "            feature 2 = 4\n",
      "               prediction = acc\n",
      "            feature 2 = 5more\n",
      "               prediction = acc\n",
      "         feature 1 = med\n",
      "            feature 2 = 2\n",
      "               feature 4 = big\n",
      "                  prediction = acc\n",
      "               feature 4 = med\n",
      "                  prediction = acc\n",
      "               feature 4 = small\n",
      "                  prediction = unacc\n",
      "            feature 2 = 3\n",
      "               prediction = acc\n",
      "            feature 2 = 4\n",
      "               prediction = acc\n",
      "            feature 2 = 5more\n",
      "               prediction = acc\n",
      "         feature 1 = vhigh\n",
      "            prediction = unacc\n",
      "feature 5 = low\n",
      "   prediction = unacc\n",
      "feature 5 = med\n",
      "   feature 3 = 2\n",
      "      prediction = unacc\n",
      "   feature 3 = 4\n",
      "      feature 0 = high\n",
      "         feature 4 = big\n",
      "            feature 1 = high\n",
      "               prediction = acc\n",
      "            feature 1 = low\n",
      "               prediction = acc\n",
      "            feature 1 = med\n",
      "               prediction = acc\n",
      "            feature 1 = vhigh\n",
      "               prediction = unacc\n",
      "         feature 4 = med\n",
      "            feature 2 = 2\n",
      "               prediction = unacc\n",
      "            feature 2 = 3\n",
      "               prediction = unacc\n",
      "            feature 2 = 4\n",
      "               feature 1 = low\n",
      "                  prediction = acc\n",
      "               feature 1 = med\n",
      "                  prediction = acc\n",
      "               feature 1 = vhigh\n",
      "                  prediction = unacc\n",
      "            feature 2 = 5more\n",
      "               prediction = acc\n",
      "         feature 4 = small\n",
      "            prediction = unacc\n",
      "      feature 0 = low\n",
      "         feature 1 = high\n",
      "            prediction = acc\n",
      "         feature 1 = low\n",
      "            feature 4 = big\n",
      "               prediction = good\n",
      "            feature 4 = med\n",
      "               feature 2 = 2\n",
      "                  prediction = acc\n",
      "               feature 2 = 3\n",
      "                  prediction = acc\n",
      "               feature 2 = 4\n",
      "                  prediction = good\n",
      "               feature 2 = 5more\n",
      "                  prediction = good\n",
      "            feature 4 = small\n",
      "               prediction = acc\n",
      "         feature 1 = med\n",
      "            feature 4 = big\n",
      "               prediction = good\n",
      "            feature 4 = med\n",
      "               feature 2 = 2\n",
      "                  prediction = acc\n",
      "               feature 2 = 3\n",
      "                  prediction = acc\n",
      "               feature 2 = 4\n",
      "                  prediction = good\n",
      "               feature 2 = 5more\n",
      "                  prediction = good\n",
      "            feature 4 = small\n",
      "               prediction = acc\n",
      "         feature 1 = vhigh\n",
      "            feature 4 = big\n",
      "               prediction = acc\n",
      "            feature 4 = med\n",
      "               feature 2 = 2\n",
      "                  prediction = unacc\n",
      "               feature 2 = 3\n",
      "                  prediction = unacc\n",
      "               feature 2 = 4\n",
      "                  prediction = acc\n",
      "               feature 2 = 5more\n",
      "                  prediction = acc\n",
      "            feature 4 = small\n",
      "               prediction = unacc\n",
      "      feature 0 = med\n",
      "         feature 1 = high\n",
      "            feature 4 = big\n",
      "               prediction = acc\n",
      "            feature 4 = med\n",
      "               feature 2 = 2\n",
      "                  prediction = unacc\n",
      "               feature 2 = 3\n",
      "                  prediction = unacc\n",
      "               feature 2 = 4\n",
      "                  prediction = acc\n",
      "               feature 2 = 5more\n",
      "                  prediction = acc\n",
      "            feature 4 = small\n",
      "               prediction = unacc\n",
      "         feature 1 = low\n",
      "            feature 4 = big\n",
      "               prediction = good\n",
      "            feature 4 = med\n",
      "               feature 2 = 2\n",
      "                  prediction = acc\n",
      "               feature 2 = 3\n",
      "                  prediction = acc\n",
      "               feature 2 = 4\n",
      "                  prediction = good\n",
      "               feature 2 = 5more\n",
      "                  prediction = good\n",
      "            feature 4 = small\n",
      "               prediction = acc\n",
      "         feature 1 = med\n",
      "            prediction = acc\n",
      "         feature 1 = vhigh\n",
      "            feature 4 = big\n",
      "               prediction = acc\n",
      "            feature 4 = med\n",
      "               feature 2 = 2\n",
      "                  prediction = unacc\n",
      "               feature 2 = 3\n",
      "                  prediction = unacc\n",
      "               feature 2 = 4\n",
      "                  prediction = acc\n",
      "               feature 2 = 5more\n",
      "                  prediction = acc\n",
      "            feature 4 = small\n",
      "               prediction = unacc\n",
      "      feature 0 = vhigh\n",
      "         feature 1 = high\n",
      "            prediction = unacc\n",
      "         feature 1 = low\n",
      "            feature 4 = big\n",
      "               prediction = acc\n",
      "            feature 4 = med\n",
      "               feature 2 = 2\n",
      "                  prediction = unacc\n",
      "               feature 2 = 3\n",
      "                  prediction = unacc\n",
      "               feature 2 = 4\n",
      "                  prediction = acc\n",
      "               feature 2 = 5more\n",
      "                  prediction = acc\n",
      "            feature 4 = small\n",
      "               prediction = unacc\n",
      "         feature 1 = med\n",
      "            feature 4 = big\n",
      "               prediction = acc\n",
      "            feature 4 = med\n",
      "               feature 2 = 2\n",
      "                  prediction = unacc\n",
      "               feature 2 = 3\n",
      "                  prediction = unacc\n",
      "               feature 2 = 4\n",
      "                  prediction = acc\n",
      "               feature 2 = 5more\n",
      "                  prediction = acc\n",
      "            feature 4 = small\n",
      "               prediction = unacc\n",
      "         feature 1 = vhigh\n",
      "            prediction = unacc\n",
      "   feature 3 = more\n",
      "      feature 0 = high\n",
      "         feature 4 = big\n",
      "            feature 1 = high\n",
      "               prediction = acc\n",
      "            feature 1 = low\n",
      "               prediction = acc\n",
      "            feature 1 = med\n",
      "               prediction = acc\n",
      "            feature 1 = vhigh\n",
      "               prediction = unacc\n",
      "         feature 4 = med\n",
      "            feature 1 = high\n",
      "               feature 2 = 2\n",
      "                  prediction = unacc\n",
      "               feature 2 = 3\n",
      "                  prediction = acc\n",
      "               feature 2 = 4\n",
      "                  prediction = acc\n",
      "               feature 2 = 5more\n",
      "                  prediction = acc\n",
      "            feature 1 = low\n",
      "               feature 2 = 2\n",
      "                  prediction = unacc\n",
      "               feature 2 = 3\n",
      "                  prediction = acc\n",
      "               feature 2 = 5more\n",
      "                  prediction = acc\n",
      "            feature 1 = med\n",
      "               prediction = acc\n",
      "            feature 1 = vhigh\n",
      "               prediction = unacc\n",
      "         feature 4 = small\n",
      "            prediction = unacc\n",
      "      feature 0 = low\n",
      "         feature 1 = high\n",
      "            feature 2 = 2\n",
      "               feature 4 = big\n",
      "                  prediction = acc\n",
      "               feature 4 = med\n",
      "                  prediction = acc\n",
      "               feature 4 = small\n",
      "                  prediction = unacc\n",
      "            feature 2 = 3\n",
      "               prediction = acc\n",
      "            feature 2 = 4\n",
      "               prediction = acc\n",
      "            feature 2 = 5more\n",
      "               prediction = acc\n",
      "         feature 1 = low\n",
      "            feature 4 = big\n",
      "               prediction = good\n",
      "            feature 4 = med\n",
      "               prediction = good\n",
      "            feature 4 = small\n",
      "               feature 2 = 2\n",
      "                  prediction = unacc\n",
      "               feature 2 = 3\n",
      "                  prediction = acc\n",
      "               feature 2 = 4\n",
      "                  prediction = acc\n",
      "               feature 2 = 5more\n",
      "                  prediction = acc\n",
      "         feature 1 = med\n",
      "            feature 4 = big\n",
      "               prediction = good\n",
      "            feature 4 = med\n",
      "               feature 2 = 2\n",
      "                  prediction = acc\n",
      "               feature 2 = 4\n",
      "                  prediction = good\n",
      "               feature 2 = 5more\n",
      "                  prediction = good\n",
      "            feature 4 = small\n",
      "               prediction = acc\n",
      "         feature 1 = vhigh\n",
      "            feature 4 = big\n",
      "               prediction = acc\n",
      "            feature 4 = med\n",
      "               feature 2 = 2\n",
      "                  prediction = unacc\n",
      "               feature 2 = 3\n",
      "                  prediction = acc\n",
      "               feature 2 = 4\n",
      "                  prediction = acc\n",
      "               feature 2 = 5more\n",
      "                  prediction = acc\n",
      "            feature 4 = small\n",
      "               prediction = unacc\n",
      "      feature 0 = med\n",
      "         feature 4 = big\n",
      "            feature 1 = high\n",
      "               prediction = acc\n",
      "            feature 1 = low\n",
      "               prediction = good\n",
      "            feature 1 = med\n",
      "               prediction = acc\n",
      "            feature 1 = vhigh\n",
      "               prediction = acc\n",
      "         feature 4 = med\n",
      "            feature 1 = high\n",
      "               feature 2 = 2\n",
      "                  prediction = unacc\n",
      "               feature 2 = 3\n",
      "                  prediction = acc\n",
      "               feature 2 = 4\n",
      "                  prediction = acc\n",
      "               feature 2 = 5more\n",
      "                  prediction = acc\n",
      "            feature 1 = low\n",
      "               feature 2 = 2\n",
      "                  prediction = acc\n",
      "               feature 2 = 3\n",
      "                  prediction = good\n",
      "               feature 2 = 5more\n",
      "                  prediction = good\n",
      "            feature 1 = med\n",
      "               prediction = acc\n",
      "            feature 1 = vhigh\n",
      "               prediction = acc\n",
      "         feature 4 = small\n",
      "            feature 1 = high\n",
      "               prediction = unacc\n",
      "            feature 1 = low\n",
      "               feature 2 = 2\n",
      "                  prediction = unacc\n",
      "               feature 2 = 4\n",
      "                  prediction = acc\n",
      "               feature 2 = 5more\n",
      "                  prediction = acc\n",
      "            feature 1 = med\n",
      "               feature 2 = 2\n",
      "                  prediction = unacc\n",
      "               feature 2 = 3\n",
      "                  prediction = acc\n",
      "               feature 2 = 4\n",
      "                  prediction = acc\n",
      "               feature 2 = 5more\n",
      "                  prediction = acc\n",
      "            feature 1 = vhigh\n",
      "               prediction = unacc\n",
      "      feature 0 = vhigh\n",
      "         feature 1 = high\n",
      "            prediction = unacc\n",
      "         feature 1 = low\n",
      "            feature 4 = big\n",
      "               prediction = acc\n",
      "            feature 4 = med\n",
      "               feature 2 = 2\n",
      "                  prediction = unacc\n",
      "               feature 2 = 3\n",
      "                  prediction = acc\n",
      "               feature 2 = 4\n",
      "                  prediction = acc\n",
      "               feature 2 = 5more\n",
      "                  prediction = acc\n",
      "            feature 4 = small\n",
      "               prediction = unacc\n",
      "         feature 1 = med\n",
      "            feature 4 = big\n",
      "               prediction = acc\n",
      "            feature 4 = med\n",
      "               feature 2 = 2\n",
      "                  prediction = unacc\n",
      "               feature 2 = 3\n",
      "                  prediction = acc\n",
      "               feature 2 = 4\n",
      "                  prediction = acc\n",
      "               feature 2 = 5more\n",
      "                  prediction = acc\n",
      "            feature 4 = small\n",
      "               prediction = unacc\n",
      "         feature 1 = vhigh\n",
      "            prediction = unacc\n"
     ]
    }
   ],
   "source": [
    "# Use 10-fold CV on Cars Dataset\n",
    "\n",
    "data = arff.loadarff('datasets/cars.arff')\n",
    "df = pd.DataFrame(data[0])\n",
    "data = np.array(df)\n",
    "\n",
    "X = data[:,:-1].astype(\"U13\")\n",
    "y = np.reshape([data[:,-1]], (-1,1)).astype(\"U13\")\n",
    "\n",
    "train_acc, test_acc, ave_acc, DTC = cross_val_10(DTClassifier, X, y)\n",
    "\n",
    "# Report Training and Test Classification Accuracies\n",
    "\n",
    "print(train_acc)\n",
    "print(test_acc)\n",
    "\n",
    "# Report Average Test Accuracy\n",
    "\n",
    "print(ave_acc)\n",
    "\n",
    "DTC.tree.dive_print(DTC.tree.root, \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Voting Dataset\n",
    "- Use this [Voting Dataset with missing values](https://raw.githubusercontent.com/cs472ta/CS472/master/datasets/voting_with_missing.arff)\n",
    "- Note that you will need to support unknown attributes in the voting data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "[0.9534883720930233, 0.9767441860465116, 0.9302325581395349, 0.9069767441860465, 0.9302325581395349, 0.8837209302325582, 1.0, 0.8372093023255814, 1.0, 0.9302325581395349]\n",
      "0.9348837209302324\n",
      "feature 3 = ?\n",
      "   feature 11 = ?\n",
      "      feature 8 = ?\n",
      "         prediction = republican\n",
      "      feature 8 = y\n",
      "         prediction = democrat\n",
      "   feature 11 = n\n",
      "      prediction = democrat\n",
      "   feature 11 = y\n",
      "      prediction = republican\n",
      "feature 3 = n\n",
      "   feature 2 = ?\n",
      "      prediction = democrat\n",
      "   feature 2 = n\n",
      "      feature 11 = ?\n",
      "         prediction = republican\n",
      "      feature 11 = n\n",
      "         feature 5 = ?\n",
      "            prediction = democrat\n",
      "         feature 5 = n\n",
      "            feature 1 = n\n",
      "               prediction = republican\n",
      "            feature 1 = y\n",
      "               prediction = democrat\n",
      "         feature 5 = y\n",
      "            prediction = democrat\n",
      "      feature 11 = y\n",
      "         prediction = democrat\n",
      "   feature 2 = y\n",
      "      prediction = democrat\n",
      "feature 3 = y\n",
      "   feature 10 = ?\n",
      "      prediction = republican\n",
      "   feature 10 = n\n",
      "      feature 15 = ?\n",
      "         feature 2 = n\n",
      "            prediction = republican\n",
      "         feature 2 = y\n",
      "            feature 6 = n\n",
      "               prediction = democrat\n",
      "            feature 6 = y\n",
      "               prediction = republican\n",
      "      feature 15 = n\n",
      "         prediction = republican\n",
      "      feature 15 = y\n",
      "         feature 12 = ?\n",
      "            feature 0 = n\n",
      "               prediction = democrat\n",
      "            feature 0 = y\n",
      "               prediction = republican\n",
      "         feature 12 = n\n",
      "            prediction = republican\n",
      "         feature 12 = y\n",
      "            prediction = republican\n",
      "   feature 10 = y\n",
      "      feature 15 = ?\n",
      "         feature 11 = ?\n",
      "            prediction = republican\n",
      "         feature 11 = n\n",
      "            prediction = democrat\n",
      "         feature 11 = y\n",
      "            prediction = democrat\n",
      "      feature 15 = n\n",
      "         feature 2 = ?\n",
      "            prediction = democrat\n",
      "         feature 2 = n\n",
      "            feature 0 = n\n",
      "               feature 1 = n\n",
      "                  prediction = democrat\n",
      "               feature 1 = y\n",
      "                  feature 12 = n\n",
      "                     prediction = democrat\n",
      "                  feature 12 = y\n",
      "                     prediction = republican\n",
      "            feature 0 = y\n",
      "               prediction = republican\n",
      "         feature 2 = y\n",
      "            prediction = democrat\n",
      "      feature 15 = y\n",
      "         feature 8 = n\n",
      "            feature 2 = n\n",
      "               prediction = republican\n",
      "            feature 2 = y\n",
      "               feature 1 = n\n",
      "                  prediction = republican\n",
      "               feature 1 = y\n",
      "                  prediction = democrat\n",
      "         feature 8 = y\n",
      "            feature 0 = n\n",
      "               prediction = democrat\n",
      "            feature 0 = y\n",
      "               feature 2 = n\n",
      "                  prediction = democrat\n",
      "               feature 2 = y\n",
      "                  prediction = republican\n"
     ]
    }
   ],
   "source": [
    "# Used 10-fold CV on Voting Dataset\n",
    "\n",
    "data = arff.loadarff('datasets/voting_with_missing.arff')\n",
    "df = pd.DataFrame(data[0])\n",
    "data = np.array(df)\n",
    "\n",
    "X = data[:,:-1].astype(\"U13\")\n",
    "y = np.reshape([data[:,-1]], (-1,1)).astype(\"U13\")\n",
    "\n",
    "train_acc, test_acc, ave_acc, DTV = cross_val_10(DTClassifier, X, y)\n",
    "\n",
    "# Report Training and Test Classification Accuracies\n",
    "\n",
    "print(train_acc)\n",
    "print(test_acc)\n",
    "\n",
    "# Report Average Test Accuracy\n",
    "\n",
    "print(ave_acc)\n",
    "\n",
    "DTV.tree.dive_print(DTV.tree.root, \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Discuss Your Results\n",
    "\n",
    "- Summarize your results from both datasets, and discuss what you observed. \n",
    "- A fully expanded tree will often get 100% accuracy on the training set. Why does this happen and in what cases might it not?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both the cars and the votes got 100% accuracy on all their training sets. I got results in the ranges given above so I am confident that my algorithm is working correctly. Both the cars and the votes got high accuracy which would suggest this is good model for classifying these data sets.\n",
    "\n",
    "I think that the training gets 100% accuracy because it usually creates a tree where all the leaf nodes are pure (only contain one possible classification). If that doesn't happen, that is probably when the training data doesn't create a tree with pure nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. (15%) For each of the two problems above, summarize in English what the decision tree has learned (i.e. look at the induced tree and describe what rules it has discovered to try to solve each task). \n",
    "- If the tree is very large you can just discuss a few of the more shallow attribute combinations and the most important decisions made high in the tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Discuss what the decision tree induced on the cars dataset has learned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing that split the data was the safety rating, the next thing to split it was how many people it carried. If the car had a low safety rating it was always classified as unacc. For the other safety options, (high or medium) if the carry capacity was two it also was classified the car as unacc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Discuss what the decision tree induced on the voting dataset has learned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing that split the voting data was their opinion on \"physician-fee-freeze\". If the value of that feature was missing, the next thing to decide on was \"export-administration-act-south-africa\". If their opinion on that was missing, it would classify the voter as republican otherwise it would say they are democrat. If their opinion on \"physician-fee-freeze\" was no, more nodes would classify that voter as democrat than republican."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 How did you handle unknown attributes in the voting problem? Why did you choose this approach? (Do not use the approach of just throwing out data with unknown attributes)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During training, my algorithm would treat the missing data as a possible value for the feature, so if there were normally 2 possible values (yes or no) it would also include missing as an option. If my algorithm encountered an unknown attribute value during testing, it treated the node it was on as a leaf. It found what classification was a majority in that node and returned that as its classification. I chose this approach because it was very easy to implement and it has a higher probability of being correct than just picking a random classification from that node."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 (10%) Use SciKit Learn's decision tree on the voting dataset and compare your results. Try different parameters and report what parameters perform the best on the test set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.1 SK Learn on Voting Dataset\n",
    "- Use this [Voting Dataset with missing values](https://raw.githubusercontent.com/cs472ta/CS472/master/datasets/voting_with_missing.arff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn score\n",
      "\n",
      "[0.95454545 0.97727273 0.97727273 0.97727273 0.97727273 0.95348837\n",
      " 0.95348837 0.88372093 0.93023256 0.93023256]\n",
      "\n",
      "average: 0.9514799154334039\n",
      "\n",
      "My DT score\n",
      "\n",
      "[0.9534883720930233, 0.9767441860465116, 0.9302325581395349, 0.9069767441860465, 0.9302325581395349, 0.8837209302325582, 1.0, 0.8372093023255814, 1.0, 0.9302325581395349]\n",
      "\n",
      "average: 0.9348837209302324\n",
      "\n",
      "sklearn score with criterion='entropy'\n",
      "\n",
      "[0.95454545 0.97727273 0.95454545 0.95454545 0.97727273 0.93023256\n",
      " 0.95348837 0.90697674 0.88372093 0.95348837]\n",
      "\n",
      "average: 0.9446088794926004\n"
     ]
    }
   ],
   "source": [
    "# Use SK Learn's Decision Tree to learn the voting dataset\n",
    "for i in range(X.shape[1]):\n",
    "    le = LabelEncoder()\n",
    "    le.fit(X[:,i])\n",
    "    X[:,i] = le.transform(X[:,i])\n",
    "\n",
    "le = LabelEncoder()\n",
    "sk_y = np.ravel(y.copy(), order='C')\n",
    "le.fit(sk_y)\n",
    "sk_y = le.transform(sk_y)\n",
    "\n",
    "\n",
    "\n",
    "skDT = DecisionTreeClassifier()\n",
    "sk_score = cross_val_score(skDT, X, sk_y, cv=10)\n",
    "\n",
    "\n",
    "# Explore different parameters\n",
    "\n",
    "# Report results\n",
    "print(\"sklearn score\\n\\n\" + str(sk_score))\n",
    "print(\"\\naverage: \" + str(sk_score.sum() / sk_score.shape[0]))\n",
    "print(\"\\nMy DT score\\n\\n\" + str(test_acc))\n",
    "print(\"\\naverage: \" + str(ave_acc))\n",
    "\n",
    "skDT = DecisionTreeClassifier(criterion='entropy')\n",
    "sk_score = cross_val_score(skDT, X, sk_y, cv=10)\n",
    "\n",
    "print(\"\\nsklearn score with criterion='entropy'\\n\\n\" + str(sk_score))\n",
    "print(\"\\naverage: \" + str(sk_score.sum() / sk_score.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I tried changing the criterion parameter in the sklearn model from default \"gini\" to \"entropy\" and the values were very similar.\n",
    "\n",
    "My algorithm and the sklearn one were usually very close although mine was a few tenths of a percent lower fairly consistently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 (10%) Choose a data set of your choice (not already used in this or previous labs) and use the SK decision tree to learn it. Experiment with different hyper-parameters to try to get the best results possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.72785623 0.74454429 0.73427471 0.73684211 0.74197689 0.75481386\n",
      " 0.74550129 0.74550129 0.76735219 0.74550129]\n",
      "0.7444164128422505\n",
      "[0.72657253 0.75866496 0.73299101 0.7381258  0.74326059 0.75353017\n",
      " 0.74678663 0.75064267 0.76863753 0.74550129]\n",
      "0.7464713181159683\n"
     ]
    }
   ],
   "source": [
    "# Use SciKit Learn's Decision Tree on a new dataset\n",
    "\n",
    "df = pd.read_csv('datasets/netflix_titles.csv')\n",
    "data = np.array(df)\n",
    "\n",
    "X = data[:,:-1]\n",
    "y = data[:,-1]\n",
    "\n",
    "for i in range(X.shape[1]):\n",
    "    le = LabelEncoder()\n",
    "    le.fit(X[:,i])\n",
    "    X[:,i] = le.transform(X[:,i])\n",
    "\n",
    "le = LabelEncoder()\n",
    "sk_y = np.ravel(y.copy(), order='C')\n",
    "le.fit(sk_y)\n",
    "sk_y = le.transform(sk_y)\n",
    "\n",
    "skDT = DecisionTreeClassifier()\n",
    "scores = cross_val_score(skDT, X, sk_y, cv=10)\n",
    "ave_score = scores.sum() / scores.shape[0]\n",
    "\n",
    "print(scores)\n",
    "print(ave_score)\n",
    "\n",
    "skDT = DecisionTreeClassifier(criterion='entropy')\n",
    "scores = cross_val_score(skDT, X, sk_y, cv=10)\n",
    "ave_score = scores.sum() / scores.shape[0]\n",
    "\n",
    "print(scores)\n",
    "print(ave_score)\n",
    "\n",
    "# Experiment with different hyper-parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I experimented with the criterion parameter again and I ran this block many times and it seemed like the \"entropy\" parameter improved the score slightly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. (5%) Visualize your decision tree for your chosen data set (using export_graphviz or another tool) and discuss what you find. If your tree is too deep to reasonably fit on one page, show only the first several levels (e.g. top 5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "digraph Tree {\n",
      "node [shape=box] ;\n",
      "0 [label=\"X[2] <= 5.5\\n7786\\n[5377, 2409]\"] ;\n",
      "1 [label=\"X[2] <= 2.5\\n1424\\n[1417, 7]\"] ;\n",
      "0 -> 1 [labeldistance=2.5, labelangle=45, headlabel=\"True\"] ;\n",
      "2 [label=\"X[2] <= 1.5\\n126\\n[121, 5]\"] ;\n",
      "1 -> 2 ;\n",
      "3 [label=\"42\\n[42, 0]\"] ;\n",
      "2 -> 3 ;\n",
      "4 [label=\"X[0] <= 398.5\\n84\\n[79, 5]\"] ;\n",
      "2 -> 4 ;\n",
      "5 [label=\"(...)\"] ;\n",
      "4 -> 5 ;\n",
      "6 [label=\"(...)\"] ;\n",
      "4 -> 6 ;\n",
      "27 [label=\"X[0] <= 673.5\\n1298\\n[1296, 2]\"] ;\n",
      "1 -> 27 ;\n",
      "28 [label=\"X[0] <= 335.0\\n1290\\n[1289, 1]\"] ;\n",
      "27 -> 28 ;\n",
      "29 [label=\"(...)\"] ;\n",
      "28 -> 29 ;\n",
      "32 [label=\"(...)\"] ;\n",
      "28 -> 32 ;\n",
      "33 [label=\"X[2] <= 4.5\\n8\\n[7, 1]\"] ;\n",
      "27 -> 33 ;\n",
      "34 [label=\"(...)\"] ;\n",
      "33 -> 34 ;\n",
      "35 [label=\"(...)\"] ;\n",
      "33 -> 35 ;\n",
      "38 [label=\"X[0] <= 280.5\\n6362\\n[3960, 2402]\"] ;\n",
      "0 -> 38 [labeldistance=2.5, labelangle=-45, headlabel=\"False\"] ;\n",
      "39 [label=\"X[0] <= 212.5\\n2124\\n[1651, 473]\"] ;\n",
      "38 -> 39 ;\n",
      "40 [label=\"X[1] <= 68.5\\n955\\n[588, 367]\"] ;\n",
      "39 -> 40 ;\n",
      "41 [label=\"(...)\"] ;\n",
      "40 -> 41 ;\n",
      "310 [label=\"(...)\"] ;\n",
      "40 -> 310 ;\n",
      "541 [label=\"X[1] <= 59.5\\n1169\\n[1063, 106]\"] ;\n",
      "39 -> 541 ;\n",
      "542 [label=\"(...)\"] ;\n",
      "541 -> 542 ;\n",
      "543 [label=\"(...)\"] ;\n",
      "541 -> 543 ;\n",
      "736 [label=\"X[1] <= 70.5\\n4238\\n[2309, 1929]\"] ;\n",
      "38 -> 736 ;\n",
      "737 [label=\"X[0] <= 293.5\\n3654\\n[2099, 1555]\"] ;\n",
      "736 -> 737 ;\n",
      "738 [label=\"(...)\"] ;\n",
      "737 -> 738 ;\n",
      "829 [label=\"(...)\"] ;\n",
      "737 -> 829 ;\n",
      "1858 [label=\"X[2] <= 6.5\\n584\\n[210, 374]\"] ;\n",
      "736 -> 1858 ;\n",
      "1859 [label=\"(...)\"] ;\n",
      "1858 -> 1859 ;\n",
      "1886 [label=\"(...)\"] ;\n",
      "1858 -> 1886 ;\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Include decision tree visualization here\n",
    "\n",
    "skDT.fit(X, sk_y)\n",
    "\n",
    "print(export_graphviz(skDT, impurity=False, label='none',max_depth=3))\n",
    "\n",
    "# Discuss what the model has learned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I honestly can't tell what is going on with this tree display so I don't know what to tell you about what the sklearn algorithm learned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. (optional 5% extra credit) Implement reduced error pruning to help avoid overfitting.  \n",
    "- You will need to take a validation set out of your training data to do this, while still having a test set to test your final accuracy. \n",
    "- Create a table comparing your decision tree implementation's results on the cars and voting data sets with and without reduced error pruning. \n",
    "- This table should compare:\n",
    "    - a) The # of nodes (including leaf nodes) and tree depth of the final decision trees \n",
    "    - b) The generalization (test set) accuracy. (For the unpruned 10-fold CV models, just use their average values in the table)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
