{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DVL7_bgmIAPR"
   },
   "source": [
    "# K-Nearest Neighbor Lab\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "6ZbYjZZZ_yLV"
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy.io import arff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sCcEPx5VIORj"
   },
   "source": [
    "## 1. (40%) Correctly implement the k-nearest neighbor (KNN) algorithm and the KNN regression algorithm\n",
    "\n",
    "### Code requirements\n",
    "- Use Euclidean distance to decide closest neighbors. \n",
    "- Include optional distance weighting for both algorithms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "_a2KSZ_7AN0G"
   },
   "outputs": [],
   "source": [
    "class KNNClassifier(BaseEstimator,ClassifierMixin):\n",
    "    def __init__(self, columntype=[], weight_type='inverse_distance', regression=False, normalize=False): ## add parameters here\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            columntype for each column tells you if continues[real] or if nominal[categoritcal].\n",
    "            weight_type: inverse_distance voting or if non distance weighting. Options = [\"no_weight\",\"inverse_distance\"]\n",
    "        \"\"\"\n",
    "        self.columntype = columntype #Note This won't be needed until part 5\n",
    "        self.weight_type = weight_type\n",
    "        self.regression = regression\n",
    "        self.normalize = normalize\n",
    "\n",
    "    def fit(self, data, labels):\n",
    "        \"\"\" Fit the data; run the algorithm (for this lab really just saves the data :D)\n",
    "        Args:\n",
    "            X (array-like): A 2D numpy array with the training data, excluding targets\n",
    "            y (array-like): A 2D numpy array with the training targets\n",
    "        Returns:\n",
    "            self: this allows this to be chained, e.g. model.fit(X,y).predict(X_test)\n",
    "        \"\"\"\n",
    "        \n",
    "        self.X = data\n",
    "        self.y = labels\n",
    "        \n",
    "        if self.normalize:\n",
    "            for i in range(self.X.shape[1]):\n",
    "                self.X[:,i] = (self.X[:,i] - self.X[:,i].min()) / (self.X[:,i].max() - self.X[:,i].min())\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, data, k):\n",
    "        \"\"\" Predict all classes for a dataset X\n",
    "        Args:\n",
    "            X (array-like): A 2D numpy array with the training data, excluding targets\n",
    "        Returns:\n",
    "            array, shape (n_samples,)\n",
    "                Predicted target values per element in X.\n",
    "        \"\"\"\n",
    "        \n",
    "        prediction = []\n",
    "        classes = np.unique(self.y)\n",
    "        \n",
    "        if self.normalize:\n",
    "            for i in range(data.shape[1]):\n",
    "                data[:,i] = (data[:,i] - data[:,i].min()) / (data[:,i].max() - data[:,i].min())\n",
    "\n",
    "        for i in range(data.shape[0]):\n",
    "            dist = np.zeros(self.X.shape[0])\n",
    "            dist = np.linalg.norm(self.X - data[i], axis=1)\n",
    "            nearest = np.zeros((k),int)\n",
    "            alt_dist = np.copy(dist)\n",
    "            for n in range(nearest.shape[0]):\n",
    "                nearest[n] = np.argmin(alt_dist)\n",
    "                alt_dist[nearest[n]] = np.inf\n",
    "            votes = np.zeros(classes.shape[0])\n",
    "            for n in range(nearest.shape[0]):\n",
    "                vote = np.where(classes == self.y[nearest[n]])[0][0]\n",
    "                if self.weight_type == 'inverted_distance':\n",
    "                    weight = 1 / (dist[n] ** 2)\n",
    "                else:\n",
    "                    weight = 1\n",
    "                votes[vote] += weight\n",
    "            prediction.append(classes[np.argmax(votes)])\n",
    "        return np.reshape(prediction, (-1,1))\n",
    "\n",
    "    #Returns the Mean score given input data and labels\n",
    "    def score(self, data, labels, k):\n",
    "        \"\"\" Return accuracy of model on a given dataset. Must implement own score function.\n",
    "        Args:\n",
    "            X (array-like): A 2D numpy array with data, excluding targets\n",
    "            y (array-like): A 2D numpy array with targets\n",
    "        Returns:\n",
    "            score : float\n",
    "                Mean accuracy of self.predict(X) wrt. y.\n",
    "        \"\"\"\n",
    "        \n",
    "        predictions = self.predict(data, k)\n",
    "        score = 0\n",
    "        for i in range(labels.shape[0]):\n",
    "            if labels[i] == predictions[i]:\n",
    "                score += 1\n",
    "        score = score / labels.shape[0]\n",
    "        \n",
    "        return score\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Debug and Evaluation\n",
    "\n",
    "Debug and Evaluate your model using the parameters below:\n",
    "\n",
    "- Use distance weighting\n",
    "- KNN = 3 (three nearest neighbors)\n",
    "- Don’t normalize the data\n",
    "- Use Euclidean Distance\n",
    "\n",
    "---\n",
    "\n",
    "### 1.1.1 Debug\n",
    "\n",
    "Debug your model by running it on the [seismic bumps](https://archive.ics.uci.edu/ml/datasets/seismic-bumps) problem.\n",
    "- Use this [training set](https://raw.githubusercontent.com/cs472ta/CS472/master/datasets/seismic-bumps_train.arff) and this [test set](https://raw.githubusercontent.com/cs472ta/CS472/master/datasets/seismic-bumps_test.arff)\n",
    "- Use distance weighting\n",
    "- KNN = 3 (three nearest neighbors)\n",
    "- Don’t normalize the data\n",
    "- Use Euclidean Distance\n",
    "\n",
    "Expected Results:\n",
    "- Acc = [93.57]\n",
    "- Link to [debug solution](https://github.com/cs472ta/CS472/blob/master/debug_solutions/seismic-bump-prediction.csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9357142857142857"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load seismic bumps data\n",
    "\n",
    "data = arff.loadarff('datasets/seismic-bumps_train.arff')\n",
    "df = pd.DataFrame(data[0])\n",
    "data = np.array(df)\n",
    "\n",
    "X = data[:,:-1].astype(np.float64)\n",
    "y = data[:,-1]\n",
    "\n",
    "knn = KNNClassifier([], 'inverse_distance')\n",
    "\n",
    "# Train on training set\n",
    "\n",
    "knn.fit(X, y)\n",
    "\n",
    "# Predict on test set\n",
    "\n",
    "data = arff.loadarff('datasets/seismic-bumps_test.arff')\n",
    "df = pd.DataFrame(data[0])\n",
    "data = np.array(df)\n",
    "\n",
    "X = data[:,:-1].astype(np.float64)\n",
    "y = data[:,-1]\n",
    "\n",
    "knn.score(X, y, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2 Evaluate\n",
    "\n",
    "We will evaluate your model based on its performance on the [diabetes](https://archive.ics.uci.edu/ml/datasets/Diabetes) problem.\n",
    "- Use this [training set](https://raw.githubusercontent.com/cs472ta/CS472/master/datasets/diabetes_train.arff) and this [test set](https://raw.githubusercontent.com/cs472ta/CS472/master/datasets/diabetes_test.arff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8411458333333334"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load diabetes data\n",
    "\n",
    "data = arff.loadarff('datasets/diabetes_train.arff')\n",
    "df = pd.DataFrame(data[0])\n",
    "data = np.array(df)\n",
    "\n",
    "X = data[:,:-1].astype(np.float64)\n",
    "y = data[:,-1]\n",
    "\n",
    "knn = KNNClassifier([], 'inverse_distance')\n",
    "\n",
    "# Train on training set\n",
    "\n",
    "knn.fit(X, y)\n",
    "\n",
    "# Predict on test set\n",
    "\n",
    "data = arff.loadarff('datasets/diabetes_test.arff')\n",
    "df = pd.DataFrame(data[0])\n",
    "data = np.array(df)\n",
    "\n",
    "X = data[:,:-1].astype(np.float64)\n",
    "y = data[:,-1]\n",
    "\n",
    "knn.score(X, y, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9vWiTdlbR2Xh"
   },
   "source": [
    "## 2. (10%) Use the k-nearest neighbor algorithm (without distance weighting) for the [magic telescope](http://archive.ics.uci.edu/ml/datasets/MAGIC+Gamma+Telescope) problem\n",
    "\n",
    "- Use this [training set](https://raw.githubusercontent.com/cs472ta/CS472/master/datasets/magic_telescope_train.arff) and this [test set](https://raw.githubusercontent.com/cs472ta/CS472/master/datasets/magic_telescope_test.arff) \n",
    "\n",
    "### 2.1\n",
    "- Try it with k=3 and without normalization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "4SSoasDQSKXb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8082808280828083"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load magic telescope data\n",
    "\n",
    "data = arff.loadarff('datasets/magic_telescope_train.arff')\n",
    "df = pd.DataFrame(data[0])\n",
    "data = np.array(df)\n",
    "\n",
    "X = data[:,:-1].astype(np.float64)\n",
    "y = data[:,-1]\n",
    "\n",
    "knn = KNNClassifier([], None)\n",
    "\n",
    "# Train/Predict without normalization\n",
    "\n",
    "knn.fit(X,y)\n",
    "\n",
    "data = arff.loadarff('datasets/magic_telescope_test.arff')\n",
    "df = pd.DataFrame(data[0])\n",
    "data = np.array(df)\n",
    "\n",
    "X_test = data[:,:-1].astype(np.float64)\n",
    "y_test = data[:,-1]\n",
    "\n",
    "knn.score(X_test,y_test,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2\n",
    "- Try it with k=3 and with normalization (input features normalized between 0 and 1). Use the normalization formula (x-xmin)/(xmax-xmin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8157815781578158"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train/Predict with normalization\n",
    "\n",
    "knn = KNNClassifier([], None, False, True)\n",
    "\n",
    "knn.fit(X,y)\n",
    "\n",
    "knn.score(X_test,y_test, 3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Discuss the accuracy results of using normalized data vs. unnormalized data*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3\n",
    "\n",
    "- Using your normalized data, create one graph with classification accuracy on the test set over k values. \n",
    "    - Use odd values of k from 1 to 15.\n",
    "- As a rough sanity check, typical knn accuracies for the magic telescope data set are 75-85%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'accuracy')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAekAAAFdCAYAAAAnlZX0AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAAttElEQVR4nO3deXhcd33v8fdX+2JZiyXvi+zEux2cRLFDSAIkJLENJECfWxIINBSScEtCykOhoaU05V5aetvSyy00EFoaEkgChM0Fy4khJhAI8ZbF4zWO7XjT2LJky9a+fe8fc6SMZdke2xqd0czn9Tx6NHPmzOhzZFkf/X7nzDnm7oiIiEjqyQo7gIiIiAxOJS0iIpKiVNIiIiIpSiUtIiKSolTSIiIiKUolLSIikqJU0iKSMDOrNbM/CTvHQGZ2h5k9F3YOkaGWE3YAERk53H1Z2BlEMolG0iIZxGL0/15khNB/VpFhZmb3m9lrZnbCzLaY2XsHPH6nmW2Ne/yyYPkUM/uxmdWbWYOZfS1Y/oCZfTfu+dVm5maWE9z/tZl9ycx+B7QCM8zsI3FfY5eZ3T0gwy1m9pKZHQ+yLo17rY/FrfenwescNbOnzGxasNzM7F/N7HDwGpvMbMEg34v3m9n6Acs+ZWYrgtvLg+/BCTM7YGZ/keD3+J/M7DkzK01kfZFUpZIWGX6vAdcApcDfAd81swkAZvY/gAeADwOjgZuBBjPLBn4OvA5UA5OAJ87ha34IuAsoCV7jMPCu4Gt8BPjXuD8GFgOPAJ8ByoBrgT0DX9DMbgH+CngfUAX8Fng8ePjG4Hmzgu38Y6BhkFz/Dcw2s5lxyz4APBbc/k/gbncvARYAz5xpI80sy8y+BVwC3OjuTWdaXyTVqaRFhpm7/9DdD7p7r7t/H3gVWBw8/DHg/7j7Oo/Z6e6vB49PBD7j7i3u3u7u53Kg1MPuvtndu929y91/4e6vBV/jWeBpYn84AHwU+La7rw4yHnD3bYO85seBf3D3re7eDfw9sCgYTXcR+4NgDmDBOnWDfC9agZ8BtwEEZT0HWBGs0gXMM7PR7n7U3TeeYRtzif2RUAG8O3htkRFNJS0yzMzsw8FU8jEzO0ZshFgZPDyF2Eh7oCnA60EZno99AzIsM7M/mFljkGF5AhkGmgZ8NW47GgEDJrn7M8DXgK8Dh83sITMbfZrXeYygpImNon8aV7B/FGR73cyeNbM3nyHPxcAtwN+5e2cC+UVSnkpaZBgFo8xvAfcAY9y9DIgQKzeIlelFgzx1HzC1bz/zAC1AUdz98YOs03+5OzPLB34E/DMwLsiwMoEMg2W6293L4j4K3f33AO7+/9z9cmAesWnvz5zmdVYDVWa2iFhZ9011E8wo3AKMBX4K/OAMebYSm7qvNbPZCeQXSXkqaZHhVUysMOsBzOwjxEbSff4D+Aszuzw4+OrioNjXAnXAl82s2MwKzOwtwXNeAq41s6nBgVKfO0uGPCA/yNBtZsuI7UPu85/AR8zs+mAf7yQzmzPI63wD+JyZzQ+2pTTYp46ZXWFmS8wsl9gfEe1A72Bh3L0L+CHwT8SmqlcHr5FnZh80s9JgneOne42413qc2H7yX5pZIn9oiKQ0lbTIMHL3LcC/AM8Dh4CFwO/iHv8h8CVio8kTxEaPFe7eA7yb2JTuXmA/8P7gOauB7wOvABuIHWB2pgwngE8SG5UeJTbFvCLu8bUEB5MBTcCzxKa2B77OT4B/BJ4ws+PEZgT63kc9mtiMwVFiB6o1ECvh03kMeAfwwwFT+h8C9gSv/3Hgg2fatiDXd4AvAs+YWfXZ1hdJZebuZ19LREREhp1G0iIiIilKJS0iIpKiVNIiIiIpSiUtIiKSolTSIiIiKSptLlVZWVnp1dXVYccQERE5Jxs2bDji7lWDPZY2JV1dXc369evPvqKIiEgKMbPXT/eYprtFRERSlEpaREQkRamkRUREUpRKWkREJEWppEVERFKUSlpERCRFqaRFRERSlEpaREQkRamkRUREUpRKWkREJEUl9bSgZrYU+CqQDfyHu395wONTge8AZcE697v7SjNbDDzUtxrwgLv/JJlZRUQks3V099DY0klDcydHWzv7bze2dNLQ0snRlr7bHbxn0STuvX5m0jMlraTNLBv4OnADsB9YZ2Yr3H1L3GqfB37g7g+a2TxgJVANRIAad+82swnAy2b23+7enay8IiKSPtydls4eGptjpdoYFGxjyxulO7B8mzsGr5gsg/KiPCqKYx+zx5cwqbxwWLYjmSPpxcBOd98FYGZPALcA8SXtwOjgdilwEMDdW+PWKQjWExGRDNXb6zS1dfWXa2NLR3/BNsSXbzDybWztpLO7d9DXysvO6i/cMaPyqB5TFLtdnEd58LmiOL9/WWlhLllZNsxbHJPMkp4E7Iu7vx9YMmCdB4CnzexeoBh4R98DZrYE+DYwDfiQRtEiIumjs7u3f0q5f2Tb3NFfsCcVbkts+rn3NMO1Ufk5VAQFO760gHkTRwdFe/LHmOJ8KkblUZyXjVk4pXuuwr5U5W3Aw+7+L2b2ZuBRM1vg7r3u/gIw38zmAt8xs1p3b49/spndBdwFMHXq1GEPLyKSadydju5eOrp66ejuoT343NHdS3vXG5+PtXbFTSt3nDLVfKJ98HGXGZQV5vaX6oyqYmqqK/pLd8yo2Ofyotjt8qI8CnKzh/m7MHySWdIHgClx9ycHy+J9FFgK4O7Pm1kBUAkc7lvB3beaWTOwADjpgtHu/hDBAWY1NTWaEheRjODudPb09pdlXzkOLM2+Ij1ToXZ09dJ+tnXibp9uCvl0crOtf3/umFF5LCwvo6IoNzadPCrvlBFvWWEuOdl641GfZJb0OmCmmU0nVs63Ah8YsM5e4Hrg4WDEXADUB8/ZFxw4Ng2YA+xJYlaREaG5o5v1exrZebiZcaMLmFJRxJTyQiqK80bM9F0mcncaWzrZd7SNfY2tHDjWRmtnDx2DletJpXn6AvYLGJaYQUFONvm5Wf2f83OyKMjNJj8ni6K8HCqKs8jPid3Pz+37HFtWkPvGY33POel2bjZlhbmUF+cxuiBHP5sXIGklHRTsPcBTxN5e9W1332xmXwTWu/sK4NPAt8zsU8QODrvD3d3MrgbuN7MuoBf4M3c/kqysIqnqWGsn6/Yc5YVdDazd00jkQNOg++WK87KZUlHE5PIiplYUMaWikCnlRUwdU8Tk8kKK8sLes5X+Wju72dcYK+F9R1vZ19jG3sZW9h9tZV9jKy2dPac8Z9CyiyvC0YW5ZyzCkz6ftF5ckeae+vycLFNxjhDmF/LnWAqpqanx9evXn31FkRRWf6KDdXsaeWFXAy/sbmT7oRO4Q15OFoumlLFkegVLpo9h7oQS6ps7+otgX1AGsdtttHWdXAiVo/KCUXeswKf23y5iQmmBphcT0N3TS11TO/sag+/zgCI+0tx50vqFudn9fzC98cfTG/dH0sFLklxmtsHdawZ7TH9ei4SorqmNF3Y18sLuRl7Y3cCu+hYg9gv+8mnlLF84gSXTK3jTlLJTDo4ZMyqfOeNHn/Ka7k5DS2dcebextyFWKi/uO8ovNtXREzccz84yJpYVxEo7bvQ9pSJWLGMyZCr9TN+3fUdbOXisfdDv29SKIt4xd1xQwLHdD1My6PsmyaWRtMgwcXf2Nbbxh90NrA1KeV9jGwAl+TnUVJezZMYYFk+vYOGkUnKTNLqNHxHuixt97wumZQcbEfaNvicHo+/4KfXi/JHzt35LR3dsmxta+/cPn3kGIv+NXQdx26wZCBlKGkmLhMDdea2+OTZK3tXI2t2NRI/H3kVYXpTL4ukV3HHVdJZMr2DuhNFkD9PJEnKys/pHfYNp7exmf1BgAwv8+dcaTtm3OqY4j8lxI8ipcdPqE8sKk/bHxmC6eno5eKytP3PfqLivkBtbTv4DpG9f/rQxxVx9cdUbuwIqtC9fUoN+AkWGSG+vsy16grW7Y/uT1+5upCEohaqS/GB/cgVLZozh4qpRoZ3B6GyK8nKYNa6EWeNKTnnM3Tna2hVXfsHnxjY2HWhiVSRKd9yUcJbBhNLCU/aD9+2brRqVf05Twu7evy9+X1yGvj8m6praTjqwLifLmFQeG/3eNH/8gFFxEeVFuZqSlpSmkhY5T909vWw+eJwXgunrtbsbOR6coGFSWSFvnVXFkhkVLJ4+huoxRWlRBmbW/37WRVPKTnm8u6eX6PH2k0bffSPZNdvrqT/RcdL6BblZbxR3MBKfUlHE2JJ8Dp/oOOn5fYXc3nXy+3SrSvKZWlHEFdXlTKmYdNIBchNKC4dthkIkGVTSIgnq6O5h0/6m4CCvRjbsaeyf+p1eWcyyBROCUq5gcvngU8npLic7i8nlsX3Xb2bMKY+3d/WctA/4jZFwG+t2N3JikAsclOTnMLmiiBlVxbx1VlX/KLxvH3k6n21KRCUtchptnT28uPdo/5HXL+49RkdwtqVZ40bxvssms3h6rJTHjS4IOe3IUJCbzcVjS7h47OBT6U1tsan0w8c7GDs6NkIuLdSUtGQulbRIoO9sXmuDkfIr+4/R1eNkGcybOJoPLpnWX8oVxXlhx007ZkZZUR5lRfreivRRSUvGOt3ZvHKyjIWTS/nTq6dz5fQxXF5dzuiC3LDjikgGUklLxjjb2bw+8faLWTJ9DJdOLRtR7/0VkfSl30SSts52Nq93LpzA4tOczUtEJBWopCXtrNl+mL/92Wb2NrYCb5zN649rpiT9bF4iIkNJJS1pZcehE9zzvY1MLCvkb941b9jP5iUiMpRU0pI2mlq7uOuR9RTm5fDIRxczobQw7EgiIhdEc36SFnp6nXse38iBY21880OXqaBFJC1oJC1p4f+s2sZvXz3CP7xvIZdPqwg7jojIkNBIWka8n710gG/+Zhe3XzmV2xZPDTuOiMiQUUnLiBY50MRnn3yFxdUVfOFd88OOIyIypFTSMmIdae7grkfWM6Y4j3+//TLycvTjLCLpRfukZUTq7O7lz767kYaWTn70P6+iclR+2JFERIacSlpGpC/+fDNr9zTy1VsXsWBSadhxRESSQvODMuI8vnYv3/3DXu6+dga3LJoUdhwRkaRRScuIsn5PI1/4WYRrZ1Xx2aVzwo4jIpJUKmkZMeqa2vj4dzcyqayQf7v1Up3qU0TSnvZJy4jQ3tXD3Y9uoK2zm8fuXEJpka7vLCLpTyUtKc/d+asfb+KV/U089KHLmTWuJOxIIiLDQtPdkvL+87nd/PjFA3zqHbO4cf74sOOIiAwblbSktOdePcLfr9zKTfPHce91F4cdR0RkWKmkJWXtbWjlnsc3cvHYUfzLHy8iSweKiUiGUUlLSmrp6ObOR9bjDt/6cA2j8nX4hIhkHpW0pJzeXucvfvgyrx4+wdc+cCnTxhSHHUlEJBQqaUk5X1uzk9pIlM8tm8s1M6vCjiMiEhqVtKSU1VsO8ZXVO3jvpZP42DXTw44jIhIqlbSkjJ2HT/Cp77/EJZNL+Yf3LcRMB4qJSGZTSUtKaGrr4s5HNlCQm8U3br+cgtzssCOJiIROh8xK6Hp6nU8+/iL7j7by2J1XMrGsMOxIIiIpQSUtofunp7bz7I56vvTeBVxRXRF2HBGRlKHpbgnVz146wDeefY0PLJnKB5dMCzuOiEhKUUlLaCIHmvjLH73CFdXlPPDu+WHHERFJOSppCcWR5g7ufnQD5UV5/PsHLycvRz+KIiIDaZ+0DLuunl7+7HsbOdLcwZMfv4qqkvywI4mIpCSVtAy7//XzLazd3cj/ff8iFk4uDTuOiEjK0hyjDKsn1u7lkedf585rpvOeSyeFHUdEJKWppGXYbHi9kb/5WYRrZlbyl0vnhB1HRCTlqaRlWESb2vn4dzcysayQf7vtUnKy9aMnInI22ictSdfe1cPdj66ntaOb731sCWVFeWFHEhEZEVTSklTuzl//JMLL+5v45ocuZ9a4krAjiYiMGJpzlKT6r9/t4Ucb93Pf9TO5af74sOOIiIwoKmlJmt/tPMKXVm7lxnnjuO/6mWHHEREZcVTSkhR7G1r5xGMbmVFZzFfev4isLF0bWkTkXKmkZci1dHRz16Pr6e11vvXhGkbl69AHEZHzod+eMqTcnc88+TI7Dp3g4Y8sprqyOOxIIiIjVlJH0ma21My2m9lOM7t/kMenmtkaM3vRzF4xs+XB8hvMbIOZbQo+X5fMnDJ0vr5mJys3Rbl/2RyunVUVdhwRkREtaSNpM8sGvg7cAOwH1pnZCnffErfa54EfuPuDZjYPWAlUA0eAd7v7QTNbADwF6BySKe5XWw/xL6t38J5FE7nzmhlhxxERGfGSOZJeDOx0913u3gk8AdwyYB0HRge3S4GDAO7+orsfDJZvBgrNTJdKSmE7Dzdz3xMvMX/iaL78R5dgpgPFREQuVDL3SU8C9sXd3w8sGbDOA8DTZnYvUAy8Y5DX+SNgo7t3JCOkXLimti7uemQ9+TlZfPNDNRTkZocdSUQkLYR9dPdtwMPuPhlYDjxqZv2ZzGw+8I/A3YM92czuMrP1Zra+vr5+WALLyXp6nfueeJG9ja08ePvlTCorDDuSiEjaSGZJHwCmxN2fHCyL91HgBwDu/jxQAFQCmNlk4CfAh939tcG+gLs/5O417l5TVaWDlMLwz09v59fb63ng5vksnl4RdhwRkbSSzJJeB8w0s+lmlgfcCqwYsM5e4HoAM5tLrKTrzawM+AVwv7v/LokZ5QL898sHefDXr3Hb4qncfuW0sOOIiKSdpJW0u3cD9xA7MnsrsaO4N5vZF83s5mC1TwN3mtnLwOPAHe7uwfMuBr5gZi8FH2OTlVXO3eaDTXzmyZepmVbO3908P+w4IiJpyWKdOPLV1NT4+vXrw46RERqaO7j5a7+jp9dZce9bGFtSEHYkEZERy8w2uHvNYI/pjGNyTrp6evnEYxupb+7gyY+/WQUtIpJEYR/dLSPM//75Fv6wq5Evv28hl0wuCzuOiEhaU0lLwn6wbh/fef51Pnb1dN532eSw44iIpD2VtCRk496jfP6nEa6ZWcn9y+aEHUdEJCOopOWsDh1v5+OPbmB8aQH/dtul5GTrx0ZEZDjot62cUXtXD3c/uoHmjm6+9eEayorywo4kIpIxdHS3nJa78/mfRnhp3zG+cftlzB5fEnYkEZGMopG0nNbDv9/Dkxv288nrZ7J0wYSw44iIZByVtAzq9zuP8L9/sZUb5o3jz6+fGXYcEZGMpJKWU+xrbOUTj21kemUxX/njN5GVpWtDi4iEQSUtJ2nt7ObOR9bT0+t868M1lBTkhh1JRCRj6cAx6efufOaHr7Dj0Am+fccVTK8sDjuSiEhG00ha+v37r1/jF5vq+OzSObxtti46JiISNpW0APDMtkP889PbuflNE7n72hlhxxEREVTSAuw83Mx9j7/EvAmj+cc/ugQzHSgmIpIKVNIZ7nh7F3c9up68nCwe+nANhXnZYUcSEZGADhzLYD29zp8/8RJ7G1r53seWMKmsMOxIIiISRyPpDPaV1dt5Ztth/vbd81gyY0zYcUREZACVdIb6+SsH+fqa17j1iincfuW0sOOIiMggVNIZaGvdcT7zw1e4fFo5f3fLfB0oJiKSolTSGejfnnmVgtwsHrz9MvJzdKCYiEiqUklnmLbOHtZsq+edl0xgbElB2HFEROQMVNIZ5tkdh2nr6mG5Lj0pIpLyVNIZZuWmKOVFuSyeXhF2FBEROQuVdAbp6O7hmW2HuXHeeHKy9U8vIpLq9Js6gzz36hGaO7pZtnB82FFERCQBKukMUhuJUlKQw1UXVYYdRUREEqCSzhBdPb2s3nKIG+aOIy9H/+wiIiOBfltniOdfa6CprYtlC3VUt4jISKGSzhC1kSjFedlcM1NT3SIiI4VKOgP09DpPb47y9jljKcjVGcZEREYKlXQGWLu7kYaWTpbpBCYiIiOKSjoDrIrUUZCbxdtmV4UdRUREzoFKOs319jq1kShvnVVFcX5O2HFEROQcqKTT3Iv7jnL4RIemukVERiCVdJqr3RQlLzuL6+aODTuKiIicI5V0GnOPTXVfPbOS0QW5YccREZFzpJJOY5sONHHgWBtLF+hc3SIiI5FKOo3VRqLkZBk3zhsXdhQRETkPKuk05e7UbqrjzReNoawoL+w4IiJyHlTSaWpb9AR7Glo11S0iMoKppNNUbSSKGdw4TyUtIjJSJVTSZvZjM3unmanUR4hVkToWV1dQVZIfdhQRETlPiZbuvwMfAF41sy+b2ewkZpILtPNwMzsONbNMU90iIiNaQiXt7r909w8ClwF7gF+a2e/N7CNmpjfgpphVkToAluosYyIiI1rC09dmNga4A/gY8CLwVWKlvTopyeS81UaiXDa1jPGlBWFHERGRC5DoPumfAL8FioB3u/vN7v59d78XGJXMgHJu9ja0svngcZ2rW0QkDSR6WaT/5+5rBnvA3WuGMI9coNr+qW7tjxYRGekSne6eZ2ZlfXfMrNzM/iw5keRC1EaiLJxUypSKorCjiIjIBUq0pO9092N9d9z9KHBnUhLJeTt4rI2X9h3TKFpEJE0kWtLZZmZ9d8wsG9C5JlPMqkgUQG+9EhFJE4nuk14FfN/MvhncvztYJilkVSTK7HElzKjSsXwiIukg0ZH0XwJrgP8ZfPwK+OzZnmRmS81su5ntNLP7B3l8qpmtMbMXzewVM1seLB8TLG82s68lvjmZ6/CJdta93siyhRpFi4iki4RG0u7eCzwYfCQkmBL/OnADsB9YZ2Yr3H1L3GqfB37g7g+a2TxgJVANtAN/AywIPuQsntp8CHf01isRkTSS6PukZ5rZk2a2xcx29X2c5WmLgZ3uvsvdO4EngFsGrOPA6OB2KXAQwN1b3P05YmUtCVgVqWNGZTGzxmmqW0QkXSQ63f1fxEbR3cDbgUeA757lOZOAfXH39wfL4j0A3G5m+4mNou9NMA8AZnaXma03s/X19fXn8tS0crSlkz/sik11xx3fJyIiI1yiJV3o7r8CzN1fd/cHgHcOwde/DXjY3ScDy4FHz+VKW+7+kLvXuHtNVVXVEMQZmVZvOURPr2uqW0QkzSR6dHdHUJ6vmtk9wAHOfjrQA8CUuPuTg2XxPgosBXD3582sAKgEDieYS4CVkTomlxcyf+Los68sIiIjRqKj1vuInbf7k8DlwO3An5zlOeuAmWY23czygFuBFQPW2QtcD2Bmc4ECIHPnrc9DU1sXv9t5hOULJ2iqW0QkzZx1JB0cpf1+d/8LoBn4SCIv7O7dwaj7KSAb+La7bzazLwLr3X0F8GngW2b2KWIHkd3h7h583T3EDirLM7P3ADcOODJcgGe2HaKrx3WWMRGRNHTWknb3HjO7+nxe3N1XEjsgLH7ZF+JubwHecprnVp/P18w0KzdFGT+6gEWTy8KOIiIiQyzRfdIvmtkK4IdAS99Cd/9xUlJJQlo6uvnNjnpuWzyVrCxNdYuIpJtES7oAaACui1vmgEo6RGu2H6aju1fn6hYRSVOJnnEsof3QMrxqN0WpHJVHTXVF2FFERCQJEippM/svYiPnk7j7nw55IklIe1cPa7Yf5j2XTiJbU90iImkp0enun8fdLgDeS3AKTwnHszvqae3sYblOYCIikrYSne7+Ufx9M3sceC4piSQhqyJRyopyWTJDU90iIukq4VNwDjATGDuUQSRxHd09/HLLIW6YO47c7PP9JxQRkVSX6D7pE5y8TzpK7BrTEoLf72zgREc3yxdqqltEJJ0lOt1dkuwgkrjaSB0l+TlcdfGYsKOIiEgSJXo96feaWWnc/bLgVJ0yzLp6enl6yyGunzuW/JzssOOIiEgSJbpD82/dvanvjrsfA/42KYnkjF7Y1cix1i6W6qhuEZG0l2hJD7Zeom/fkiFUG6mjKC+bt83O3Otni4hkikRLer2ZfcXMLgo+vgJsSGYwOVVPr/PU5ihvnz2WglxNdYuIpLtES/peoBP4PvAE0A58IlmhZHDr9zRypLlTl6UUEckQiR7d3QLcn+Qscha1kSj5OVm8fY7eoi4ikgkSPbp7tZmVxd0vN7OnkpZKTtEbTHVfO6uKUfk6HEBEJBMkOt1dGRzRDYC7H0VnHBtWL+0/Rl1Tuy5LKSKSQRIt6V4zm9p3x8yqGeSqWJI8qyJRcrON6+eOCzuKiIgMk0TnTf8aeM7MngUMuAa4K2mp5CTuTm2kjrdcXElpYW7YcUREZJgkNJJ291VADbAdeBz4NNCWxFwSZ/PB4+xrbNNUt4hIhkn0AhsfA+4DJgMvAVcCzwPXJS2Z9KuN1JGdZdwwTyUtIpJJEt0nfR9wBfC6u78duBQ4lqxQ8gZ3p3ZTlCtnVFBRnBd2HBERGUaJlnS7u7cDmFm+u28DZicvlvTZcaiZXUdadK5uEZEMlOiBY/uD90n/FFhtZkeB15MVSt5QG6nDDG6ar6O6RUQyTaJnHHtvcPMBM1sDlAKrkpZK+q2KRLliWgVjSwrCjiIiIsMs0enufu7+rLuvcPfOZASSN+yqb2Zb9ITO1S0ikqHOuaRl+NRGogAqaRGRDKWSTmGrIlEWTSljYllh2FFERCQEKukUta+xlU0HmnQCExGRDKaSTlGrgqnuZXrrlYhIxlJJp6jaSB3zJoxm6piisKOIiEhIVNIpKNrUzsa9x1i+UFPdIiKZTCWdglZF6gB0ljERkQynkk5BtZEoM8eO4uKxo8KOIiIiIVJJp5gjzR2s29PIsoUaRYuIZDqVdIp5evMheh299UpERFTSqaY2Ukf1mCLmjC8JO4qIiIRMJZ1CjrV28vxrDSxbOAEzCzuOiIiETCWdQlZvOUR3r2uqW0REAJV0SqmNRJlUVsjCSaVhRxERkRSgkk4RJ9q7eO7VIyxdMF5T3SIiAqikU8Yz2w7T2dOrs4yJiEg/lXSKWLmpjnGj87l0SnnYUUREJEWopFNAa2c3z+6o56b548nK0lS3iIjEqKRTwK+319Pe1avLUoqIyElU0imgNhJlTHEei6dXhB1FRERSiEo6ZO1dPTyz9RA3zh9Htqa6RUQkjko6ZL999QgtnT2a6hYRkVOopENWG6mjtDCXN180JuwoIiKSYlTSIers7mX1lkO8Y+44crP1TyEiIidTM4To968d4UR7t87VLSIig1JJh2hVJMqo/ByunlkZdhQREUlBSS1pM1tqZtvNbKeZ3T/I41PNbI2ZvWhmr5jZ8rjHPhc8b7uZ3ZTMnGHo7unlqc1RrpszloLc7LDjiIhICspJ1gubWTbwdeAGYD+wzsxWuPuWuNU+D/zA3R80s3nASqA6uH0rMB+YCPzSzGa5e0+y8g63tbsbOdrapaluERE5rWSOpBcDO919l7t3Ak8AtwxYx4HRwe1S4GBw+xbgCXfvcPfdwM7g9dJGbSRKYW42b5s9NuwoIiKSopJZ0pOAfXH39wfL4j0A3G5m+4mNou89h+diZneZ2XozW19fXz9UuZOut9dZtTnK22ZXUZinqW4RERlc2AeO3QY87O6TgeXAo2aWcCZ3f8jda9y9pqqqKmkhh9qGvUepP9HBUk11i4jIGSRtnzRwAJgSd39ysCzeR4GlAO7+vJkVAJUJPnfEqt0UJS8ni+vmaKpbREROL5kj6XXATDObbmZ5xA4EWzFgnb3A9QBmNhcoAOqD9W41s3wzmw7MBNYmMeuwcXdWReq4dmYlJQW5YccREZEUlrSSdvdu4B7gKWArsaO4N5vZF83s5mC1TwN3mtnLwOPAHR6zGfgBsAVYBXwiXY7sfnl/Eweb2lmqc3WLiMhZJHO6G3dfSeyAsPhlX4i7vQV4y2me+yXgS8nMF4baSB05WcYNc8eFHUVERFJc2AeOZZTYVHeUqy6upLRIU90iInJmKulhtKXuOK83tOoEJiIikhCV9DBaFYmSZXDjPE11i4jI2amkh1FtJMqS6WMYMyo/7CgiIjICqKSHyauHTrDzcDPLFmqqW0REEqOSHia1kSgAN81XSYuISGJU0sOkNhKlZlo540YXhB1FRERGCJX0MNhzpIWtdcd1rm4RETknKulh0DfVrZIWEZFzoZIeBqsidVwyuZTJ5UVhRxERkRFEJZ1k+4+28vL+JpbpXN0iInKOVNJJtiqY6tZZxkRE5FyppJNsVSTKnPElVFcWhx1FRERGGJV0Eh0+3s6GvUdZvlBT3SIicu5U0kn01OYo7prqFhGR86OSTqKVm6JcVFXMzHElYUcREZERSCWdJA3NHbywu0FT3SIict5U0kmyesshel0nMBERkfOnkk6SlZEoUyuKmDdhdNhRRERkhFJJJ0FTaxe/33mEZQvHY2ZhxxERkRFKJZ0Ev9x6iO5e11nGRETkgqikk6A2UsfE0gLeNLk07CgiIjKCqaSHWHNHN7959Qg3LdBUt4iIXBiV9BB7ZtthOrt79dYrERG5YCrpIbYqUkdVST6XTy0PO4qIiIxwKukh1NbZw5pt9dw0fxxZWZrqFhGRC6OSHkLP7jhMW1cPy3VUt4iIDAGV9BCqjUQpL8pl8fSKsKOIiEgaUEkPkY7uHn619TA3zhtPTra+rSIicuHUJkPkuVeP0NzRzbKFOle3iIgMDZX0EKmNRCkpyOGqiyrDjiIiImlCJT0Eunp6Wb3lEDfMHUdejr6lIiIyNNQoQ+D51xpoauvSZSlFRGRIqaSHQG0kSnFeNtfOqgo7ioiIpBGV9AXq6XWe3hzl7XPGUpCbHXYcERFJIyrpC7R2dyMNLZ26LKWIiAw5lfQFWhWpoyA3i7fN1lS3iIgMLZX0BejtdVZtjvLWWVUU5+eEHUdERNKMSvoCvLjvKIeOd2iqW0REkkIlfQFqN0XJy87iurljw44iIiJpSCV9ntyd2kiUq2dWMrogN+w4IiKShlTS52nTgSYOHGvTCUxERCRpVNLnqTYSJTvLuGHuuLCjiIhImlJJnwd3Z1UkylUXjaG8OC/sOCIikqZU0udh+6ET7D7SoqluERFJKpX0eVi5KYoZ3DhPJS0iIsmjkj4PqyJ1LK6uoKokP+woIiKSxlTS52jn4WZ2HGpmmaa6RUQkyVTS52hVpA6ApTrLmIiIJJlK+hzVRqJcNrWM8aUFYUcREZE0p5I+B3sbWtl88LjO1S0iIsMiqSVtZkvNbLuZ7TSz+wd5/F/N7KXgY4eZHYt77B/NLBJ8vD+ZORNV2z/Vrf3RIiKSfEm7vqKZZQNfB24A9gPrzGyFu2/pW8fdPxW3/r3ApcHtdwKXAYuAfODXZlbr7seTlTcRtZEoCyaNZkpFUZgxREQkQyRzJL0Y2Onuu9y9E3gCuOUM698GPB7cngf8xt273b0FeAVYmsSsZ1XX1MZL+45pqltERIZNMkt6ErAv7v7+YNkpzGwaMB14Jlj0MrDUzIrMrBJ4OzAliVnPalUkCqC3XomIyLBJ2nT3OboVeNLdewDc/WkzuwL4PVAPPA/0DHySmd0F3AUwderUpAas3RRl9rgSZlSNSurXERER6ZPMkfQBTh79Tg6WDeZW3pjqBsDdv+Tui9z9BsCAHQOf5O4PuXuNu9dUVVUNUexTHT7RzrrXG1m2UKNoEREZPsks6XXATDObbmZ5xIp4xcCVzGwOUE5stNy3LNvMxgS3LwEuAZ5OYtYzenrzIdzR/mgRERlWSZvudvduM7sHeArIBr7t7pvN7IvAenfvK+xbgSfc3eOengv81swAjgO3u3t3srKeTW2kjhmVxcwap6luEREZPkndJ+3uK4GVA5Z9YcD9BwZ5XjuxI7xDd7Slkz/sauTjb51B8EeDiIjIsNAZx85i9ZZD9PS6prpFRGTYqaTPYmWkjsnlhcyfODrsKCIikmFU0mfQ1NbF73YeYdmC8ZrqFhGRYaeSPoNnth2iq8dZtlBT3SIiMvxU0mdQuynK+NEFLJpcFnYUERHJQCrp02jp6ObZHfUsXTCerCxNdYuIyPBTSZ/Gmu2H6eju1bm6RUQkNCrp06iNRKkclUdNdUXYUUREJEOppAfR3tXDmm2HuXH+eLI11S0iIiFRSQ/i2R31tHb2sFwnMBERkRCppAexKhKlrCiXJTM01S0iIuFJletJp5RbFk1kyfQKcrP1N4yIiIRHJT2It80eG3YEERERTXeLiIikKpW0iIhIilJJi4iIpCiVtIiISIpSSYuIiKQolbSIiEiKUkmLiIikKJW0iIhIilJJi4iIpCiVtIiISIpSSYuIiKQoc/ewMwwJM6sHXg87xwWoBI6EHSKJtH0jW7pvH6T/Nmr7Utc0d68a7IG0KemRzszWu3tN2DmSRds3sqX79kH6b6O2b2TSdLeIiEiKUkmLiIikKJV06ngo7ABJpu0b2dJ9+yD9t1HbNwJpn7SIiEiK0khaREQkRamkQ2ZmU8xsjZltMbPNZnZf2JmSwcyyzexFM/t52FmGmpmVmdmTZrbNzLaa2ZvDzjSUzOxTwc9mxMweN7OCsDNdCDP7tpkdNrNI3LIKM1ttZq8Gn8vDzHghTrN9/xT8fL5iZj8xs7IQI16wwbYx7rFPm5mbWWUY2YaaSjp83cCn3X0ecCXwCTObF3KmZLgP2Bp2iCT5KrDK3ecAbyKNttPMJgGfBGrcfQGQDdwabqoL9jCwdMCy+4FfuftM4FfB/ZHqYU7dvtXAAne/BNgBfG64Qw2xhzl1GzGzKcCNwN7hDpQsKumQuXudu28Mbp8g9gt+UriphpaZTQbeCfxH2FmGmpmVAtcC/wng7p3ufizUUEMvByg0sxygCDgYcp4L4u6/ARoHLL4F+E5w+zvAe4Yz01AabPvc/Wl37w7u/gGYPOzBhtBp/g0B/hX4LJA2B1uppFOImVUDlwIvhBxlqP1fYv9xekPOkQzTgXrgv4Lp/P8ws+KwQw0Vdz8A/DOxkUkd0OTuT4ebKinGuXtdcDsKjAszTJL9KVAbdoihZma3AAfc/eWwswwllXSKMLNRwI+AP3f342HnGSpm9i7gsLtvCDtLkuQAlwEPuvulQAsje6r0JMG+2VuI/TEyESg2s9vDTZVcHnvLS9qMxOKZ2V8T28X2vbCzDCUzKwL+CvhC2FmGmko6BZhZLrGC/p67/zjsPEPsLcDNZrYHeAK4zsy+G26kIbUf2O/ufbMfTxIr7XTxDmC3u9e7exfwY+CqkDMlwyEzmwAQfD4ccp4hZ2Z3AO8CPujp997bi4j9Ifly8LtmMrDRzMaHmmoIqKRDZmZGbH/mVnf/Sth5hpq7f87dJ7t7NbEDjp5x97QZibl7FNhnZrODRdcDW0KMNNT2AleaWVHws3o9aXRgXJwVwJ8Et/8E+FmIWYacmS0ltsvpZndvDTvPUHP3Te4+1t2rg981+4HLgv+fI5pKOnxvAT5EbIT5UvCxPOxQck7uBb5nZq8Ai4C/DzfO0AlmCJ4ENgKbiP3OGNFndjKzx4Hngdlmtt/MPgp8GbjBzF4lNnvw5TAzXojTbN/XgBJgdfA75huhhrxAp9nGtKQzjomIiKQojaRFRERSlEpaREQkRamkRUREUpRKWkREJEWppEVERFKUSlpETsvMqge70pCIDA+VtIiISIpSSYtIQsxsRnARkSvCziKSKXLCDiAiqS847ekTwB3pdpUhkVSmkhaRs6kidi7r97l7Op2XXCTlabpbRM6midiFNq4OO4hIptFIWkTOphN4L/CUmTW7+2NhBxLJFCppETkrd28xs3cRu4pSs7uvCDuTSCbQVbBERERSlPZJi4iIpCiVtIiISIpSSYuIiKQolbSIiEiKUkmLiIikKJW0iIhIilJJi4iIpCiVtIiISIr6/2MPhGpElcXXAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train/Predict with normalization using k=1,3,...,15\n",
    "\n",
    "accuracies = []\n",
    "\n",
    "for g in range(1,16, 2):\n",
    "    accuracies.append(knn.score(X_test, y_test, g))\n",
    "\n",
    "# Graph classification accuracy over k\n",
    "\n",
    "ks = np.arange(1, 16, 2)\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "ax.plot(ks, accuracies)\n",
    "ax.set_title(\"accuracies vs k\")\n",
    "ax.set_xlabel(\"k\")\n",
    "ax.set_ylabel(\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For the rest of the experiments use only normalized data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SIRG42TgSR4x"
   },
   "source": [
    "## 3. (10%) Use the regression variation of your algorithm (without distance weighting) for the [housing price prediction](https://www.cs.toronto.edu/~delve/data/boston/bostonDetail.html) problem.\n",
    "\n",
    "- Use this [training set](https://raw.githubusercontent.com/cs472ta/CS472/master/datasets/housing_train.arff) and this [test set](https://raw.githubusercontent.com/cs472ta/CS472/master/datasets/housing_test.arff).\n",
    "- Use Mean Square Error (MSE) on the test set as your accuracy metric for this case.\n",
    "    - Do not normalize regression output values\n",
    "- Graph MSE on the test set with odd values of k from 1 to 15\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "KBGUn43ASiXW"
   },
   "outputs": [],
   "source": [
    "# Load housing price prediction data\n",
    "\n",
    "# Train/Predict using k=1,3,...,15\n",
    "\n",
    "# Graph MSE over k\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v19fpixqTe-7"
   },
   "source": [
    "## 4. (15%) Repeat your experiments for magic telescope and housing using distance-weighted (inverse of distance squared) voting and discuss your results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "ZCPFUAGTS2sX"
   },
   "outputs": [],
   "source": [
    "# Train/Predict magic telescope using distance-weighted voting\n",
    "\n",
    "# Train/Predict housing using distance-weighted voting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Discuss your results*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. (10%) Use the k-nearest neighbor algorithm to solve the [credit-approval](https://archive.ics.uci.edu/ml/datasets/Credit+Approval) (credit-a) problem.\n",
    "\n",
    "- Use this [dataset](https://raw.githubusercontent.com/cs472ta/CS472/master/datasets/credit_approval.arff)\n",
    "    - Use a 70/30 split of the data for the training/test set\n",
    "- Note that this set has both continuous and nominal attributes, together with don’t know values. \n",
    "- Implement and justify a distance metric which supports continuous, nominal, and don’t know attribute values\n",
    "    - You need to handle don't knows with the distance metric, not by imputing a value.\n",
    "    - More information on distance metrics can be found [here](https://www.jair.org/index.php/jair/article/view/10182/24168).\n",
    "- Use your own choice for k.\n",
    "- As a rough sanity check, typical knn accuracies for the credit data set are 70-80%.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset and split into train/test sets\n",
    "\n",
    "# Train/Predict credit-approval\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Explain and justify your distance metric*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oBBmeNQ7jvcQ"
   },
   "source": [
    "## 6. (15%) Use the scikit's KNN Classifier on magic telescope and KNN Regressor on housing and compare your results.\n",
    "\n",
    "- Try out different hyperparameters to see how well you can do. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "OFQv70W2VyqJ"
   },
   "outputs": [],
   "source": [
    "# Train/Predict magic telescope using scikit's KNN\n",
    "\n",
    "# Train/Predict housing using scikit's KNN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BqSFAXwlk3Ms"
   },
   "source": [
    "*Report your comparison*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cTlK-kijk8Mg"
   },
   "source": [
    "## 7. (optional 5% extra credit): For the best value of k for any one of the datasets, implement a reduction algorithm that removes data points in some rational way such that performance does not drop too drastically on the test set given the reduced training set.\n",
    "\n",
    "- Compare your performance on the test set for the reduced and non-reduced versions and give the number (and percentage) of training examples removed from the original training set. How well does your reduction algorithm work?\n",
    "    - Note that performance for magic telescope is classification accuracy and for housing it is mean squared error.\n",
    "    - Magic Telescope has about 12,000 instances and if you use a leave one out style of testing for your data set reduction, then your algorithm will run slow since that is n2 at each step.\n",
    "    - If you wish, you may use a random subset of 2,000 of the magic telescope instances.\n",
    "    - More information on reduction techniques can be found [here](http://axon.cs.byu.edu/~martinez/classes/478/slides/IBL.pdf).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5iY77P7gk1Nh"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "lab 1 - perceptron",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
